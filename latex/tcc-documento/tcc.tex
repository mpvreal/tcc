\documentclass[
	% -- opções da classe memoir --
	12pt,				% tamanho da fonte
	openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
	oneside,			% twoside para impressão em verso e anverso. Oposto a oneside
	a4paper,			% tamanho do papel. 
	% -- opções da classe dc-uel --
	tccpreliminar,			% tipo do trabalho (opções: tcc, tccpreliminar, dissertacao, qualificacaoms)
					% - tcc (Versão para a Banca do TCC ou Versão Final do TCC)
					% - tccpreliminar (Versão Preliminar do TCC)
					% - dissertação (Versão para a Banca da Dissertação ou Versão Final/Revisada da Dissertação)
					% - qualificacaoms (Qualificação de Mestrado)
	]{ABNT-DC-UEL}


% ---
% PACOTES
% ---

% ---
% Pacotes fundamentais https://www.overleaf.com/project/64b9646755fec68416aede1d
% ---
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{pdfpages}			% Inclusão de (páginas de) arquivos PDF no documento
% ---
		
% ---
% Pacotes adicionais, usados apenas no âmbito do Modelo Canônico do abnteX2
% ---
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{tikz, pgfplots}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{mathtools}
\usepackage{graphbox}
\usepackage{mathabx}
\usepackage[export]{adjustbox}
\usepackage{hyperref}

\graphicspath{ {./img/} }

\usetikzlibrary{positioning}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\pgfplotsset{compat=1.18}
\lstset{basicstyle=\ttfamily}

\newenvironment{algoritmo}[1][] {
    \begin{algorithm}[#1]
         \selectlanguage{portuguese}
         \floatname{algorithm}{Algoritmo}
         \renewcommand{\algorithmicprocedure}{\textbf{procedimento}}
         \renewcommand{\algorithmicrequire}{\textbf{Dados:}}
         \renewcommand{\algorithmicensure}{\textbf{Saída:}}
         \renewcommand{\algorithmicfunction}{\textbf{função}}
         \renewcommand{\algorithmicif}{\textbf{se}}
         \renewcommand{\algorithmicthen}{\textbf{então}}
         \renewcommand{\algorithmicelse}{\textbf{senão}}
         \renewcommand{\algorithmicforall}{\textbf{para todo}}
         \renewcommand{\algorithmicfor}{\textbf{para}}
         \renewcommand{\algorithmicrepeat}{\textbf{repita}}
         \renewcommand{\algorithmicuntil}{\textbf{até}}
         \renewcommand{\algorithmicloop}{\textbf{repita}}
         \renewcommand{\algorithmicwhile}{\textbf{enquanto}}
         \renewcommand{\algorithmicdo}{\textbf{faça}}
         \renewcommand{\algorithmicend}{\textbf{fim}}
         \renewcommand{\algorithmicreturn}{\textbf{retorne}}
      }
      {\end{algorithm}
}

% ---
% Informações de dados para CAPA, FOLHA DE ROSTO e outros elementos
% ---
\titulo{Aplicações do Aprendizado de Máquina na geração de código \textit{spill}}
\tituloingles{Machine Learning applications in spill code generation}
\palavraschave{Compiladores. Aprendizado de Máquina. Código spill. Alocação de registradores. Otimização}
\palavraschaveingles{Compilers. Machine Learning. Spill code. Register allocation. Optimization.}
\autor{Matheus Pires Vila Real}
\citacaoautor{REAL, M}
\data{2023}

\diadefesa{24 de novembro}
\orientador{Prof. Dr. Wesley Attrot} % É membro nato e presidente da Banca Examinadora
% \coorientador{Prof(a). Dr(a). Nome do(a) Coorientador(a)} % Pode ou não ser membro da Banca; se for, deve ser incluído como membro a seguir
\membrobancadois{Prof. Dr. Segundo Membro da Banca}
\instmembrobancadois{Universidade Estadual de Londrina}
\membrobancatres{Prof. Dr. Terceiro Membro da Banca}
\instmembrobancatres{Universidade Estadual de Londrina}

% ---
% compila o indice
% ---
\makeindex
% ---

% ----
% Início do documento
% ----
\begin{document}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing 

% ----------------------------------------------------------
% ELEMENTOS PRÉ-TEXTUAIS
% ----------------------------------------------------------
% \pretextual

% ---
% Capa (elemento obrigatório)
% ---
\imprimircapa
% ---

% ---
% Folha de rosto (elemento obrigatório)
% (o * indica que haverá a ficha bibliográfica)
% ---
\imprimirfolhaderosto*
% ---


% ---
% Ficha bibliografica (elemento obrigatório para versões finais de TCC e dissertação)
% ---

% Isto é um exemplo de Ficha Catalográfica, ou ``Dados internacionais de
% catalogação-na-publicação''. Você poderá utilizar o site da biblioteca para 
% gerar esta ficha através do link: http://www.uel.br/bc/ficha/. Quando estiver
% com o documento, salve-o como PDF no diretório do seu projeto e substitua todo
% o conteúdo de implementação deste arquivo pelo comando abaixo:
%
\begin{fichacatalografica}
    \includepdf{ficha_catalografica.pdf}
\end{fichacatalografica}


% ---

% ---
% Folha de aprovação (elemento obrigatório) ==> deve ser omitida no caso de tccpreliminar
% ---

% Isto é um exemplo de Folha de aprovação, elemento obrigatório da NBR
% 14724/2011 (seção 4.2.1.3). Você pode utilizar este modelo até a aprovação
% do trabalho. Após isso, substitua todo o conteúdo deste arquivo por uma
% imagem da página assinada pela banca com o comando abaixo:
%
% \includepdf{folhadeaprovacao_final.pdf}
\imprimirfolhadeaprovacao
% ---

% ---
% Dedicatória (elemento opcional)
% ---
% \begin{dedicatoria}
%   \vspace*{\fill}
%   \hspace{.4\textwidth}
%   \begin{minipage}{.5\textwidth}
%     \begin{flushright}
%       \textit{Este trabalho é dedicado às crianças adultas que, quando pequenas, sonharam em se tornar cientistas.}
%     \end{flushright}  
%   \end{minipage}
% \end{dedicatoria}
% ---

% ---
% Agradecimentos (elemento opcional, mas fortemente recomendado)
% ---
\begin{agradecimentos}
% Os agradecimentos principais são direcionados à Gerald Weber, Miguel Frasson,
% Leslie H. Watter, Bruno Parente Lima, Flávio de Vasconcellos Corrêa, Otavio Real
% Salvador, Renato Machnievscz\footnote{Os nomes dos integrantes do primeiro
% projeto abn\TeX\ foram extraídos de
% \url{http://codigolivre.org.br/projects/abntex/}} e todos aqueles que
% contribuíram para que a produção de trabalhos acadêmicos conforme
% as normas ABNT com \LaTeX\ fosse possível.

% Agradecimentos especiais são direcionados ao Centro de Pesquisa em Arquitetura
% da Informação\footnote{\url{http://www.cpai.unb.br/}} da Universidade de
% Brasília (CPAI), ao grupo de usuários
% \emph{latex-br}\footnote{\url{http://groups.google.com/group/latex-br}} e aos
% novos voluntários do grupo
% \emph{\abnTeX}\footnote{\url{http://groups.google.com/group/abntex2} e
% \url{http://abntex2.googlecode.com/}}~que contribuíram e que ainda
% contribuirão para a evolução do \abnTeX.

\end{agradecimentos}
% ---

% ---
% Epígrafe (elemento opcional)
% ---
\begin{epigrafe}
  \vspace*{\fill}
  \hspace{.4\textwidth}
  \begin{minipage}{.5\textwidth}   
    \begin{flushright}
	\textit{
    ``Não vos amoldeis às estruturas deste mundo,
      mas transformai-vos pela renovação da mente,
      a fim de distinguir qual é a vontade de Deus:
      o que é bom, o que Lhe é agradável, o que é perfeito.\\
      (Bíblia Sagrada, Romanos 12, 2))}
    \end{flushright}
  \end{minipage}
\end{epigrafe}
% ---

% ---
% RESUMOS
% ---

% ---
% Resumo em Português (elemento obrigatório)
% ---
\begin{resumo}
A alocação de registradores é uma das otimizações de código mais significativas do processo de compilação de um programa. Mas, devido à natureza dos algoritmos empregados nas implementações tradicionais, ela caracteriza-se como um prolema NP-completo, o qual é difícil de se resolver de maneira ótima. Nesse contexto, ao longo dos anos foram sendo propostas heurísticas e ajustes visando tornar as técnicas de geração de código \textit{spill} mais precisas e menos custosas. Com o crescimento da relevância do aprendizado de máquina (\textit{machine learning}) --- área da inteligência artificial, que engloba o desenvolvimento de modelos complexos de categorização e predição treinados de maneira algorítmica --- surge a perspectiva de integração de ambas as áreas. Isto posto, este trabalho se propõe a vislumbrar o estado da arte da aplicação do aprendizado de máquina na alocação de registradores e investigar as possibilidades práticas de implementação de alocadores utilizando modelos treinados por \textit{machine learning}.
\end{resumo}
% ---

% ---
% Resumo em Inglês (elemento obrigatório)
% ---
% O ambiente Abstract (com A maiúsculo) é definido no estilo dc-uel
\begin{Abstract}
Register allocation is highlighted as one of the key code optimizations throughout a program's compilation process. It is, however, a NP-complete problem, due to the nature of the traditional implementations, which are unable to obtain optimal solutions in reasonable time. In this context, several heuristics and adjustments have been proposed over the course of the years in order to improve the precision and the speed of register allocators. Machine learning, in the other hand, is a field of artificial intelligence encompassing the development of complex classification and prediction models which are trained in an algorithmic way, that grew in relevance and became widely researched recently. Therefore, efforts to apply machine learning techniques to register allocation, aiming to improve spill code generation, arose. This work is intended to examine the current state-of-the-art of the integration of both fields and investigate the implementation possiblities of register allocators that widely employ machine learning models in their inner workings.
\end{Abstract}
% ---

% ---
% Lista de ilustrações (elemento opcional, mas fortemente recomendado)
% ---
\pdfbookmark[0]{\listfigurename}{lof}
\listoffigures*
\cleardoublepage
% ---

% ---
% Lista de tabelas (elemento opcional, mas fortemente recomendado)
% ---
\pdfbookmark[0]{\listtablename}{lot}
\listoftables*
\cleardoublepage
% ---

% ---
% Lista de abreviaturas e siglas (elemento opcional)
% ---
\begin{siglas}
  % \item[ABNT] Associação Brasileira de Normas Técnicas
  % \item[BNDES] Banco Nacional de Desenvolvimento Econômico e Social
  % \item[IBGE] Instituto Nacional de Geografia e Estatística
  % \item[IBICT] Instituto Brasileiro de Informação em Ciência e Tecnologia
  % \item[NBR] Norma Brasileira
  \item[CPU] \textit{Central processing unit}
  \item[GPU] \textit{Graphics processing unit}
  \item[CFG] \textit{Control-flow graph}
  \item[IR] \textit{Intermediate representation}
  \item[SSA] \textit{Static single-assignment}
  \item[JIT] \textit{Just-in-time}
  \item[PBQP] \textit{Partitioned boolean quadratic problem}
  \item[LLVM] \textit{Low-level virtual machine}
  \item[PCA] \textit{Principal component analysis}
  \item[ANN] \textit{Artificial neural network}
  \item[LSTM] \textit{Long short-term memory}
  \item[MIR] \textit{Machine intermediate representation}
  \item[GGNN] \textit{Gated graph neural network}
  \item[GCN] \textit{Graph convolutional network}
  \item[ASP] \textit{Answer set programming}
  \item[PPO] \textit{Proximal policy optimization}
  \item[MCTS] \textit{Monte Carlos search tree}
\end{siglas}
% ---

% ---
% Lista de símbolos (elemento opcional)
% ---
% \begin{simbolos}
%   \item[$ \Gamma $] Letra grega Gama
%   \item[$ \Lambda $] Lambda
%   \item[$ \zeta $] Letra grega minúscula zeta
%   \item[$ \in $] Pertence
% \end{simbolos}
% ---

% ---
% Sumario (elemento obrigatório)
% ---
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\cleardoublepage
% ---



% ----------------------------------------------------------
% ELEMENTOS TEXTUAIS
% ----------------------------------------------------------
\textual
\pagestyle{dc-uel-header} % Configura cabeçalho para apresentar apenas números de página


% ----------------------------------------------------------
% Introdução
% ----------------------------------------------------------
\chapter{Introdução}
Os compiladores constituem uma das classes de programa na Ciência da Computação, cuja principal função é a tradução de código-fonte de uma linguagem de programação para outra. Usualmente, esse processo é empregado para transformar código de alto nível em linguagem de máquina de baixo nível, executável diretamente pelo processador de determinada arquitetura-alvo. \cite{aho:07}.

Para atingir esse objetivo, o compilador deve submeter o programa original a uma série de análises --- léxica, sintática e semântica --- a fim de criar uma representação lógica de sua estrutura e prosseguir com a geração de código. Entre essas duas etapas, é desejável efetuar algumas otimizações a fim de tornar o binário final mais eficiente do ponto de vista de execução e mais coerente com as especificidades da arquitetura-alvo \cite{muchnick:97}.

Dentre as etapas de otimização, destaca-se a alocação de registradores, onde o compilador deve distribuir os registradores para as variáveis utilizadas ao longo do fluxo de execução do programa. Os registradores são componentes microarquiteturais diretamente disponíveis ao processador, e caracterizam-se como as unidades de memória de mais rápido acesso \cite{mittal:16}. Contudo, sendo eles um recurso finito, surge a possibilidade de não haverem registradores o suficiente para comportar todos os valores e resultados intermediários em memória de uma única vez \cite{aho:07}.

Nesses casos, há a necessidade de se mapear algumas variáveis para a memória principal, e o compilador deve então introduzir no código instruções de acesso à memória para salvar e recuperar os valores lá armazenados. Essas instruções são denominadas código \textit{spill}, ou \textit{spill code} \cite{briggs:92}. Um esquema de alocação ideal deve buscar minimizar o tráfego entre a memória principal e a CPU, visto que essas operações, em comparação com acessar os registradores, são significativamente mais lentas e dispendiosas do ponto de vista energético. As operações em memória representam de 50\% a 75\% dos gastos de energia de um sistema computacional \cite{verma:06}, e um alocador sofisticado pode proporcionar uma melhora de até 250\% no tempo de execução de um programa comparado a um alocador simples \cite{pereira:08}.

A abordagem tradicional emprega a coloração de grafo como abstração para representar o processo de atribuição dos registradores físicos para as variáveis virtuais. Nesse modelo, os valores em memória --- chamados de registradores virtuais da representação intermediária do código --- são expressos como os nós de um grafo a ser colorido; as arestas representam as relações de interferência entre os registradores virtuais, isto é, a presença de intersecções entre o tempo de vida dos valores em memória, enquanto que a coloração em si seria o processo de encontrar registradores físicos disponíveis para cada variável \cite{chaitin:81}.

Contudo, produzir uma alocação eficiente não é uma tarefa trivial. A coloração de grafos é um problema NP-completo, isto é, não há algoritmos determinísticos que a resolvam em tempo polinomial \cite{karp:72}, e descobrir a mera quantidade de cores necessárias para colorir um grafo é um problema difícil \cite{garey:76}. Ademais, uma implementação ingênua pode introduzir \textit{spill code} desnecessário ao longo de todo o tempo de vida de um registrador virtual \cite{bergner:97}, ou realizar escolhas ruins sobre quais variáveis enviar para a memória principal, ao eleger valores frequentemente utilizados no código e que exigirão uma grande quantidade de acessos ou escritas à memória \cite{bernstein:89}.

Ao longo dos anos, soluções para se contornar as dificuldades em se gerar código \textit{spill} de maneira eficiente foram propostas: ajustes no algoritmo original, visando tornar a introdução de instruções \texttt{load}/\texttt{store} mais precisa nos pontos de interferência necessários \cite{chaitin:82, briggs:92, briggs2:92, cooper:98}, e a utilização de heurísticas para cálculo de custo de \textit{spill}, visando melhorar a qualidade das escolhas de quais variáveis mapear para a memória principal. Infelizmente, as heurísticas dependem de uma boa quantidade de ajustes para propiciar um desempenho adequado. O desenvolvimento de um conjunto de heurísticas para uma arquitetura-alvo específica ainda é feito através de tentativa e erro, e o ajuste fino das funções prioritárias é um processo tedioso \cite{amarasinghe:03}.

O aprendizado de máquina (\textit{machine learning}), por sua vez, é uma área da inteligência artificial que abrange o desenvolvimento de modelos e agentes inteligentes treinados de maneira algorítmica. Eles realizam tarefas de predição e classificação probabilísticas a partir de parâmetros de entrada, e são calibrados após sucessivas iterações de treinamento, onde os resultados de saída são confrontados com um conjunto de dados previamente conhecidos sobre o problema, de modo a se calcular um erro e ajustar os parâmetros internos do modelo para minimizá-lo \cite{sharma:21}.

Nas últimas décadas, o aprendizado de máquina e a inteligência artificial como um todo vem avançando consideravelmente, graças ao crescimento do poder computacional das máquinas e conforme cada vez mais dados são gerados e coletados \cite{alpaydin:20}. Esse cenário expande os horizontes para a integração de ambas as áreas, que almeja o desenvolvimento de melhores heurísticas e métodos para otimizar a alocação de registradores empregando técnicas de aprendizado de máquina. Trabalhos vêm sendo publicados explorando a interdisciplinaridade de ambas as áreas e trazendo resultados animadores ou, ao menos, de interesse, como é o caso das pesquisas de Stephenson \textit{et al.}, Das \textit{et al.} e VenkataKeerthy \textit{et al.} \cite{amarasinghe:03, das:20, venkatakeerthy:23}.

Este trabalho se propõe a investigar a aplicação das técnicas de aprendizado de máquina na alocação de registradores, particularmente sua utilidade na geração de código \textit{spill}. Ele irá contemplar o estado da arte da alocação de registradores e, apoiado no conhecimento acadêmico sobre a área, serão propostos métodos de alocação e heurísticas que utilizam \textit{machine learning}. Utilizando as ferramentas disponíveis na infraestrutura LLVM --- um \textit{framework} utilizado na implementação de compiladores de produção --- é esperado desenvolver um modelo de aprendizado que auxilie nas etapas da alocação tradicional, e que tenha um desempenho ao menos comparável ao dos alocadores do \textit{framework} \cite{llvm:01}.

% Explicar seções

% ----------------------------------------------------------
% PARTE
% ----------------------------------------------------------
% A organização dos capítulos em partes só é recomendada caso o texto seja muito extenso
% Não é comum dividir o trabalho em partes em TCCs e dissertações de mestrado

%\part{Preparação da pesquisa}

% ----------------------------------------------------------
% Capitulo com exemplos de comandos inseridos de arquivo externo 
% ----------------------------------------------------------

% \include{abntex2-modelo-include-comandos}

\chapter{Alocação de Registradores}

A alocação de registradores é uma etapa de otimização responsável por assinalar registradores físicos às variáveis presentes na representação intermediária (\textit{IR}) produzida pelo \textit{front-end} do compilador. A \textit{IR} é produzida após a conclusão das análises léxica, sintática e semântica no código-fonte, onde o compilador extrai as informações sobre o fluxo de execução e operações aritméticas e consiste, usualmente, de uma simplificação com menos abstrações do programa inicial como, por exemplo, o código de três endereços  \cite{aho:07}.

O código de três endereços representa o programa como uma sequência de instruções de até três operandos, compostas por expressões de atribuição com operações binárias ou desvios. Para fins de análise, o código é organizado em um grafo onde cada nó contém uma sequência de instruções, chamado grafo de controle de fluxo (\textit{control flow graph}, ou CFG). Ele denota o fluxo de execução do programa e permite ao compilador realizar as análises necessárias para se efetuar otimizações no código, chamadas de \textit{control flow analysis} \cite{allen:70}.

A Figura \ref{fig:codigo-exemplo} é um exemplo de um trecho de código qualquer, em linguagem C, que apresenta operações aritméticas e uma estrutura de controle. Após a análise dos elementos do código-fonte, o modelo abstrato obtido é similar à árvore da Figura \ref{fig:ast}. A partir desse modelo, é produzida a representação intermediária equivalente, mostrada na Figura \ref{fig:cfg-exemplo}.

\begin{figure}[ht]
    \centering
    \begin{lstlisting}[language=c, frame=single]
        do {
            j = a + a * (c * d - d);
            i--;
        } while (i > 0);
        i = j;
    \end{lstlisting}
    \caption{Exemplo de código C apresentando expressões aritméticas e estruturas de controle.}
    \label{fig:codigo-exemplo}
\end{figure}

\begin{figure}
    \centering
    \begin{tikzpicture} [level 1/.style={sibling distance=40mm},level 2/.style={sibling distance=20mm},
                    level 3/.style={sibling distance=15mm}]
        \node {programa}
        child {node {do..while}
          child {node {>}
            child {node {i}}
            child {node {0}}
          }
          child {node {=}
            child {node {j}}
            child {node {+}
                child {node {a}}
                child {node {*}
                    child {node {a}}
                    child {node {-}
                        child {node {*}
                            child {node {c}}
                            child {node {d}}
                        }
                        child {node {d}}
                    }
                }
            }
          }
          child {node {- -} child {node {i}}}
        }
        child {node {=}
            child {node {i}}
            child {node {j}}
        };
    \end{tikzpicture}
    \caption{Árvore sintática abstrata representando o código da Figura \ref{fig:codigo-exemplo}.}
    \label{fig:ast}
\end{figure}

\begin{figure}
    \centering
    \begin{tikzpicture}[
    CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=5mm, align=center},
    ]
        \node[CFG] (B0) {$\texttt{t}_1\ \texttt{:= c*d}$\\
                         $\texttt{t}_2\ \texttt{:= t}_1\texttt{-d}$\\
                         $\texttt{t}_3\ \texttt{:= a*t}_2$\\
                         $\texttt{t}_4\ \texttt{:= a+t}_3$\\
                         $\texttt{t}\ \texttt{:= t}_4$\\
                         $\texttt{t}\ \texttt{:= i-1}$\\
                         \texttt{if i>0}};
        \node[CFG, above = of B0] (start) {\texttt{entry}};
        \node[left = 3mm of B0] {$B_1$};
        
        \node[CFG] (B1) [below=of B0] {$\texttt{i := j}$};
        \node[left = 3mm of B1] {$B_2$};
        \node[CFG, below = of B1] (stop) {\texttt{exit}};
        
        \node[right = 0.2cm of B0] {\texttt{true}};
        \coordinate[above right = 2.3cm and 2cm of B0] (a) {};
        \coordinate[below right = 2.3cm and 2cm of B0] (b) {};

        \draw[-latex, very thick] (B0.south) to node[left] {\texttt{false}} (B1.north);
        \draw[-latex, very thick] (B0.south) .. controls (b) and (a)  .. ([xshift=-7mm] B0.north east);
        \draw[-latex, very thick] (start) -- (B0.north);
        \draw[-latex, very thick] (B1.south) -- (stop);
    \end{tikzpicture}
    \caption{Grafo de controle de fluxo equivalente gerado a partir da árvore da Figura \ref{fig:ast}.}
    \label{fig:cfg-exemplo}
\end{figure}

Devido à natureza da representação intermediária, os valores intermediários computados no cálculo de expressões aritméticas complexas e avaliação de estruturas de controle são expostos na forma de variáveis temporárias, que se juntam às variáveis definidas pelo programador para formar o conjunto dos valores em memória utilizados pelo programa. Esses valores são denominados registradores virtuais, e é trabalho do alocador decidir onde eles serão armazenados \cite{muchnick:97}.

Os registradores virtuais são endereços simbólicos que serão traduzidos em endereços reais após o processo de alocação de registradores. Eles são gerados de maneira incremental pelo compilador de modo a substituir os endereços reais, para possibilitar uma representação abstrata do programa na forma de código de três endereços e permitir a realização de inúmeras otimizações, sem que a disposição dos endereços de memória seja um entrave para a manipulação da IR \cite{muchnick:97}.

\section{\textit{Liveness Analysis} e Interferências}

Em posse de uma representação intermediária contendo registradores virtuais, o compilador prossegue para a tarefa de mapeá-los para endereços de memória ou registradores físicos. Como dois valores de memória não podem ocupar um único registrador físico ao mesmo tempo, o número de registradores de uso geral disponibilizados pela arquitetura-alvo pode vir a tornar-se um empecilho caso o número de variáveis seja grande demais. Os processadores x86-64 fabricados por companhias como Intel e AMD, por exemplo, possuem comumente 16 registradores de uso geral \cite{amd:06}; arquiteturas RISC como ARMv8, MIPS e SPARC apresentam respectivamente 31, 30 e 32 registradores \cite{elkady:14}.

Sendo assim, para corretamente alocar os recursos de memória da CPU de modo a comportar as variáveis utilizadas pelo programa, o compilador deve computar os pontos de utilização dos valores ao longo do programa e determinar quando uma variável está viva ou não. Esse processo é denominado análise de longevidade, ou \textit{liveness analysis}, e é uma variação da análise de fluxo de dados também efetuada em outras otimizações. 

\begin{figure}[hb]
    \centering
    \begin{tikzpicture}[
    CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=5mm, align=center},
    ]
        \node[CFG] (B0) {$\texttt{a := 3}$\\
                         $\texttt{b := a+1}$\\
                         $\texttt{b := b+1}$\\
                         $\texttt{print(b)}$\\
                         $\texttt{c := 1}$\\
                         $\texttt{e := a+2}$\\
                         \texttt{goto L}};
        \node[CFG] (B1) [below=of B0] {$\texttt{print(c)}$\\$\vdots$};
        \draw[->, thick] (B0.south) -- (B1.north);
        
        \draw[black, ultra thick] (-1.3, -0.75) -- (-1.3, 1.35);
        \filldraw[black, thick] (-1.3, -0.75) circle (3pt);
        \filldraw[black, thick] (-1.3, 1.35) circle (3pt);
        \node at (-1.3, 1.75) {$\texttt{a}$};
        
        \draw[black, ultra thick] (-1.7, 0.25) -- (-1.7, 0.90);
        \filldraw[black, thick] (-1.7, 0.25) circle (3pt);
        \filldraw[black, thick] (-1.7, 0.90) circle (3pt);
        \node at (-1.7, 1.30) {$\texttt{b}$};

        \draw[black, ultra thick] (1.3, -0.75) -- (1.3, -3);
        \filldraw[black, thick] (1.3, -0.75) circle (3pt);
        \filldraw[black, thick] (1.3, -3) circle (3pt);
        \node at (1.3, -0.35) {$\texttt{c}$};

        \draw[black, ultra thick] (1.7, -1.3) -- (1.7, -3.5);
        \filldraw[black, thick] (1.7, -1.3) circle (3pt);
        \draw[black, ultra thick, dotted] (1.7, -3.5) -- (1.7, -4.10);
        \node at (1.7, -0.9) {$\texttt{e}$};
    \end{tikzpicture}
    \caption{Dois blocos básicos contendo as variáveis \texttt{a}, \texttt{b}, \texttt{c} e \texttt{e}, com seus respectivos \textit{live ranges} indicados.}
    \label{fig:liverange-exemplo}
\end{figure}

Uma variável é dita viva no ponto que antecede diretamente a execução de uma instrução se ela contém um valor que será utilizado futuramente ou, em outra palavras, se ela será lida antes da próxima redefinição de seu valor. O conjunto de todos os pontos pelos quais uma variável contendo um valor está viva é chamado de \textit{live range}. Entretanto, uma única variável pode ser quebrada em vários \textit{live ranges}, conforme o valor que ela armazena não será mais utilizado ou é redefinido, dando origem a objetos alocáveis distintos \cite{aho:07}.

Quando dois \textit{live ranges} $v_i$ e $v_j$ se sobrepõe em determinado ponto, diz-se que há uma interferência entre eles. Em outras palavras, eles interferem pois a intersecção entre seus conjuntos de pontos não é vazia. Isso significa que ambos os valores presentes em $v_i$ e $v_j$ não podem ser mapeados para o mesmo registrador físico, pois ambos devem ser mantidos em memória integralmente para algum uso posterior. A Figura \ref{fig:liverange-exemplo} mostra dois blocos básicos com variáveis e seus respectivos \textit{live ranges}. Nesse exemplo, a variável $a$ interfere com as variáveis $b$ e $c$.

Se dois \textit{live ranges} $v_i$ e $v_j$ estiverem conectados por uma instrução de cópia na forma $v_i := v_j$ e não interferirem entre si, os dois valores podem ser armazenados no mesmo registrador. Esse ato é denominado coalescimento, ou \textit{coalescing}, e pode promover um ganho significativo na qualidade do código gerado ao eliminar instruções de cópia desnecessárias \cite{appel:96, chaitin:82, briggs:92}.

\section{Geração de Código \textit{Spill}}

O número de registradores físicos necessários para comportar os \textit{live ranges} em um ponto do código é uma métrica conhecida como pressão de registradores \cite{braun:09}. Quando esse número excede a quantidade de registradores disponíveis para a alocação, faz-se necessário armazenar algum \textit{live range} na memória principal. Para isso, são introduzidas as instruções de acesso a memória \texttt{store}, para escrever, e \texttt{load} para recuperar um valor em memória. 

\begin{figure}[hb]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}[
        CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=5mm, align=center},
        ]
            \node[CFG] (B0) {$\texttt{v}_1\ \texttt{:= x}$\\
                            $\texttt{v}_2\ \texttt{:= v}_1\texttt{+2}$\\
                            $\texttt{v}_3\ \texttt{:= v}_2\texttt{+1}$\\
                            $\vdots$\\
                            $\texttt{v}_1\ \texttt{:= v}_1\texttt{+1}$\\
                            $\vdots$\\
                            $\texttt{v}_5\ \texttt{:= 4}$\\
                            $\texttt{print(v}_1\texttt{)}$};
            
            \draw[black, ultra thick] (1.5, -1.70) -- (1.5, 1.70);
            \filldraw[black, thick] (1.5, -1.70) circle (3pt);
            \filldraw[black, thick] (1.5, 1.70) circle (3pt);
            \node at (1.5, 2.10) {$\texttt{v}_1$};
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{0.1\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (0,5) -- (1,5);
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}[
        CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=5mm, align=center},
        ]
            \node[CFG] (B0) {$\texttt{v}_1\ \texttt{:= x}$\\
                             $\texttt{store(v}_1\texttt{)}$\\
                             $\texttt{load(v}_1\texttt{)}$\\
                             $\texttt{v}_2\ \texttt{:= v}_1\texttt{+2}$\\
                             $\texttt{v}_3\ \texttt{:= v}_2\texttt{+1}$\\
                             $\vdots$\\
                             $\texttt{load(v}_1\texttt{)}$\\
                             $\texttt{v}_1\ \texttt{:= v}_1\texttt{+1}$\\
                             $\vdots$\\
                             $\texttt{v}_5\ \texttt{:= 4}$\\
                             $\texttt{load(v}_1\texttt{)}$\\
                             $\texttt{print(v}_1\texttt{)}$};
            
            % \draw[black, ultra thick] (1.5, 2.70) -- (1.5, -1.70);
            \node at (1.5, 3.1) {$\texttt{v}_1$};
            \filldraw[black, thick] (1.5, 2.70) circle (3pt);
            \filldraw[black, thick] (1.5, 1.75) circle (3pt);
            \filldraw[black, thick] (1.5, -0.4) circle (3pt);
            \filldraw[black, thick] (1.5, -2.65) circle (3pt);
        \end{tikzpicture}}
    \end{subfigure}
    \caption{Exemplo de bloco básico antes e depois do \textit{spill} do \textit{live range} $\texttt{v}_1$.}
    \label{fig:spill-exemplo}
\end{figure}

Essas instruções são denominadas código \textit{spill}, e tem por efeito fragmentar o \textit{live range} escolhido ao redor do ponto de grande pressão, a fim de reduzi-la \cite{chaitin:81}. Ao longo do curso de execução de um programa, uma mesma variável pode ser ser armazenada em registradores e posteriormente ser enviada para a memória, e ter seu \textit{live range} particionado \cite{eisl:16}. A Figura \ref{fig:spill-exemplo} mostra um bloco básico antes e depois do \textit{spill} da variável $v_1$, cujo tempo de vida é decomposto em várias porções menores, aliviando a pressão em determinados pontos.

Esse artifício, no entanto, produz um código mais lento. As instruções de acesso à memória consomem significativamente mais ciclos do que operações aritméticas simples em registradores e desvios. A inserção de \textit{spill code} em locais inapropriados, como em laços de repetição ou trechos que serão frequentemente executados, podem causar um grande \textit{overhead} que derruba a performance do executável gerado. Um alocador eficiente tem a tarefa de minimizar a quantidade de acessos à memória gerados o quanto for possível, e ser preciso em suas escolhas sobre quais variáveis selecionar para \textit{spill} e a colocação das instruções.

\section{Alocação via Coloração de Grafos}

A alocação de registradores por coloração de grafos é a abordagem dominante para o desenvolvimento de alocadores na atualidade. Ela foi implementada pela primeira vez por Chaitin \textit{et al.} em 1980, em um compilador experimental da linguagem PL/I para o IBM System/370 \cite{chaitin:81}, e foi o primeiro método amplamente aplicado para alocação global de registradores, onde os registradores são alocados para toda a unidade de compilação (função) de uma só vez, em vez de alocá-los por bloco \cite{eisl:16}.

\begin{figure}[hbt]
    \centering
    \begin{tikzpicture}

        % Definindo vértices    
        \foreach \pos/\name/\color in {{(0,2)/A/cyan}, {(2,1)/B/green}, {(1,0)/C/cyan},
                                       {(-1,0)/D/red}, {(0,-1)/E/green}, {(2,-2)/F/red}}
            \node[circle, fill=\color, draw=black] (\name) at \pos {$\name$};
        
        % Definindo arestas
        \foreach \source/\target in {A/B, B/C, C/F, D/A, E/C, F/E, D/E}
            \draw (\source) -- (\target);
    
    \end{tikzpicture}
    
    \caption{Exemplo de grafo de interferência colorido com três cores.}
    \label{fig:grafo-petersen}
\end{figure}

Seja $G = (V, E)$ um grafo não-direcionado, onde os vértices $v \in V$ representam os \textit{live ranges} e as arestas $e \in E$, as interferências, tal que $e_n = (v_i, v_j)$ simboliza a existência de uma interferência entre $v_i$ e $v_j$. O grafo $G$ é dito $k$-colorível se houver uma função $cor: V \to \{1,...,k\}$ tal que $cor(v_i) \ne cor(v_j)$, para todo $v_i$ e $v_j$ em que existir uma aresta
$e_n = (v_i, v_j)$. A alocação é reduzida, então, a encontrar o mapeamento dado pela função $cor$, onde $k$ é o número de registradores físicos presentes na arquitetura-alvo.

Entretanto, computar uma solução ótima não é trivial. A coloração de grafo é um clássico problema NP-completo \cite{karp:72} --- determinar a $k$-colorabilidade de um grafo possui complexidade exponencial e logo torna-se inviável para casos que envolvem muitos registradores virtuais \cite{lawler:76, bjorklund:09}, e a mera tarefa de determinar o número mínimo de cores para se colorir um grafo é um problema NP-\textit{hard} \cite{garey:76}. A Figura \ref{fig:grafo-petersen} exibe uma possível instância de grafo de interferência, formado pelas variáveis $A$, $B$, $C$, $D$, $E$ e $F$, e colorido com três cores.

\subsection{Alocador de \textit{Chaitin}}

Chaitin \textit{et al.} \cite{chaitin:82} formalizaram, em 1982, seu algoritmo de alocação global de registradores via coloração de grafo. A Figura \ref{fig:alocador-chaitin} esquematiza a execução do alocador, que consiste em construir um grafo de interferência e manipulá-lo em etapas que estão descritas a seguir:

\begin{enumerate}
    \item \textit{Renumber} --- encontrar todos os \textit{live ranges} dentro do escopo da função ou procedimento, e lhes atribuir um identificador único;
    \item \textit{Build} --- construir o grafo de interferência $G = (V,E)$, onde cada \textit{live range} se torna um vértice $v\in 
    V$ e as arestas $(v_i,v_j)\in E$ são adicionadas conforme o código é varrido de maneira retrógrada e as interferências são descobertas;
    \item \textit{Coalesce} --- combinar os \textit{live ranges} que são conectados por uma única instrução de cópia $v_i:=v_j$ e não interferem entre si, de modo que os vértices correspondentes no grafo sejam combinados em um único vértice $v_{ij}$. A instrução de cópia pode ser removida da IR, e as etapas de \textit{build} e \textit{coalesce} devem ser refeitas devido à modificação no código;
    \item \textit{Spill cost} --- computar o custo de \textit{spill} para cada \textit{live range}. Esse custo é uma estimativa do aumento no tempo de execução se um dado vértice for mapeado para a memória principal, aumento esse que é proporcional ao número de vezes que as instruções de \texttt{store} e \texttt{load} inseridas serão executadas;
    \item \textit{Simplify} --- remover os vértices tal que $grau(v)<k$, onde $grau(v)$ é o número de arestas de $v$ e $k$ é número de cores. Isso pode ser feito pois, se um vértice possui um número de arestas menor do que o número de cores, ele certamente é colorível. Sendo assim, após a remoção, o vértice deve ser adicionado a uma pilha auxiliar $S$, que serve como estrutura de controle da ordem de remoção.
    
    Se não houverem vértices aptos a serem removidos, algum deve ser escolhido para sofrer \textit{spill}. A prioridade de \textit{spill} é calculada utilizando o custo calculado na etapa anterior, sendo igual a $custo(v)/grau(v)$. O vértice que apresentar o menor custo então é escolhido e a etapa \textit{spill code} é acionada; 
    \item \textit{Spill code} --- o código é alterado com a inserção de instruções de acesso à memória, e o algoritmo deve reiniciar a partir da etapa \textit{renumber};
    \item \textit{Select} --- assinalar cores aos vértices de $G$, os desempilhando de $S$ um a um, na ordem reversa à que foram removidos na etapa anterior. Se a geração de \textit{spill code} não foi acionada, seguramente todos os vértices receberão uma cor tal que $cor(v_i)\ne cor(v_j)$ onde $v_i$ e $v_j$ são vizinhos.
\end{enumerate}

\begin{figure}
    \centering
    \begin{tikzpicture}[
        node distance= 1cm and 0.5cm,
        box/.style={draw, rectangle, minimum width=2.1cm, minimum height=1cm, align=center},
        arrow/.style={very thick, ->, >=stealth},
    ]
        \node[box] (renumber) {\textit{Renumber}};
        \node[box, right = of renumber] (build) {\textit{Build}};
        \node[box, right = of build] (coalesce) {\textit{Coalesce}};
        \node[box, right = of coalesce] (cost) {\textit{Spill cost}};
        \node[box, right = of cost] (simplify) {\textit{Simplify}};
        \node[box, right = of simplify] (select) {\textit{Select}};
        \node[box, above = 0.5cm of coalesce] (spill) {\textit{Spill code}};
        \coordinate[above = of simplify] (bezier1);
        \coordinate[above = of renumber] (bezier2);
        \coordinate[below = of coalesce] (bezier3);
        \coordinate[below = of build] (bezier4);
        \coordinate[left = of renumber] (start);

        \draw[arrow] (renumber) -- (build);
        \draw[arrow] (build) -- (coalesce);
        \draw[arrow] (coalesce) -- (cost);
        \draw[arrow] (cost) -- (simplify);
        \draw[arrow] (simplify) -- (select);

        \draw[arrow] (simplify.north) .. controls (bezier1) .. (spill.east);
        \draw[arrow] (spill.west) .. controls (bezier2) .. (renumber.north);
        \draw[arrow] (coalesce.south) .. controls (bezier3) and (bezier4) .. (build.south);
        \draw[arrow] (start) -- (renumber.west);
    \end{tikzpicture}
    \caption{Esquema do algoritmo de Chaitin \cite{chaitin:82}.}
    \label{fig:alocador-chaitin}
\end{figure}

\subsection{Alocador de \textit{Chaitin-Briggs}}

Briggs \cite{briggs:92} propôs uma série de alterações ao algoritmo de Chaitin a fim de corrigir uma série de defeitos que sua versão inicial apresentava. Notavelmente, ele sugeriu um atraso na etapa de geração de \textit{spill code} para produzir alocações mais eficientes e alguns ajustes no processo de coalescimento do alocador, a fim de otimizar o tratamento de instruções de cópia.

Em um trabalho anterior, de 1989 \cite{briggs:89}, Briggs \textit{et al.} demonstraram que o alocador de Chaitin era ineficiente na sua etapa de \textit{simplify}, ao gerar \textit{spill} em grafos que são trivialmente coloríveis. Um exemplo usado pelo próprio Briggs é o de um grafo em forma de losango, possuindo quatro vértices com duas arestas cada e que é visivelmente colorível para um número de cores $k=2$, como mostrado na Figura \ref{fig:grafo-diamante}. No entanto, o alocador de Chaitin fatalmente enviaria algum registrador virtual para a memória pois, na etapa de \textit{simplify}, não haveriam vértices tal que $\mathit{grau}(v)<2$ e algum deles e a ativação da etapa \textit{spill code} seria imediata.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[node/.style={draw,circle}]
        \node[node, fill=green] (v_1) {$v_1$};
        \node[node, below left = of v_1, fill=yellow] (v_2) {$v_2$};
        \node[node, below right = of v_1, fill=yellow] (v_3) {$v_3$};
        \node[node, below left = of v_3, fill=green] (v_4) {$v_4$};
        
        \draw[-, very thick] (v_1) -- (v_2);
        \draw[-, very thick] (v_2) -- (v_4);
        \draw[-, very thick] (v_3) -- (v_4);
        \draw[-, very thick] (v_3) -- (v_1);
        
    \end{tikzpicture}
    \caption{Grafo $2$-colorível que seria incorretamente colorido pelo alocador de Chaitin.}
    \label{fig:grafo-diamante}
\end{figure}

Para solucionar o problema da realização precipitada de \textit{spill}, Briggs propôs adiar a etapa de \textit{spill code} para depois da etapa de \textit{select}. Assim, se por acaso não houverem vértices aptos a serem removidos durante a fase de simplificação, é escolhido um candidato a \textit{spill} dentre os vértices cujo grau é maior que o número de cores $k$. Por ser somente um candidato, o alocador ainda deve considerar a possibilidade de colorir esse vértice no futuro e ele pode portanto ser removido do grafo, permitindo destravar o algoritmo e continuar a etapa de \textit{simplify}. 

Posteriormente, na etapa de \textit{select}, será avaliada a necessidade de se efetuar \textit{spill} das variáveis candidatas: se ao desempilhar um vértice $v$ tal que $\mathit{grau}(v)>k$ não for possível encontrar uma cor para $v$, somente então a geração de \textit{spill} code é ativada. Dessa forma, o alocador torna-se capaz de colorir vértices cujo número de arestas é maior do que o número de cores disponíveis, preservando a ordem de coloração produzida pelo alocador de Chaitin. Esssa técnica foi denominada \textit{optimistic coloring}, e é ilustrada pela Figura \ref{fig:alocador-briggs}, exibindo o fluxo básico de execução de um alocador ao estilo de Briggs.

Além disso, o algoritmo de Chaitin, na etapa de \textit{coalesce}, poderia transformar um grafo $k$-colorível em um não-colorível ao combinar dois vértices $v_i$ e $v_j$ em um único vértice $v_{ij}$, onde $grau(v_{ij})\geq k$. Dessa forma, Briggs \textit{et al.} \cite{briggs2:92} propuseram o \textit{conservative coalescing}, que consiste em somente coalescer dois vértices se a união de ambos tiver um grau menor do que o número de cores, sendo assim garantidamente colorível.

\begin{figure}[hb]
    \centering
    \begin{tikzpicture}[
        node distance= 1cm and 0.5cm,
        box/.style={draw, rectangle, minimum width=2.1cm, minimum height=1cm, align=center},
        arrow/.style={very thick, ->, >=stealth},
    ]
        \node[box] (renumber) {\textit{Renumber}};
        \node[box, right = of renumber] (build) {\textit{Build}};
        \node[box, right = of build] (coalesce) {\textit{Coalesce}};
        \node[box, right = of coalesce] (cost) {\textit{Spill cost}};
        \node[box, right = of cost] (simplify) {\textit{Simplify}};
        \node[box, right = of simplify] (select) {\textit{Select}};
        \coordinate[above = of select] (bezier1);
        \coordinate[above = of renumber] (bezier2);
        \coordinate[below = of coalesce] (bezier3);
        \coordinate[below = of build] (bezier4);
        \coordinate[left = of renumber] (start);
        \coordinate[above = of cost] (d);
        \node[box, left = of d] (spill) {\textit{Spill code}};

        \draw[arrow] (renumber) -- (build);
        \draw[arrow] (build) -- (coalesce);
        \draw[arrow] (coalesce) -- (cost);
        \draw[arrow] (cost) -- (simplify);
        \draw[arrow] (simplify) -- (select);

        \draw[arrow] (select.north) .. controls (bezier1) .. (spill.east);
        \draw[arrow] (spill.west) .. controls (bezier2) .. (renumber.north);
        \draw[arrow] (coalesce.south) .. controls (bezier3) and (bezier4) .. (build.south);
        \draw[arrow] (start) -- (renumber.west);
    \end{tikzpicture}
    \caption{Esquema do algoritmo de Briggs, com a etapa de geração de \textit{spill code} adiada.}
    \label{fig:alocador-briggs}
\end{figure}

\subsection{\textit{Iterated Register Coalescing}}

Em 1996, George e Appel \cite{appel:96} propuseram uma maneira diferente de coalescer os registradores virtuais: o \textit{iterated register coalescing} é um método mais agressivo de combinar vértices no grafo de interferência, sem adicionar novos \textit{spills} desnecessariamente. Ele consistia em executar as etapas de \textit{simplify} e \textit{coalesce} iterativamente, com a inclusão de uma etapa adicional denominada \textit{freeze}, como descrito a seguir:

\begin{enumerate}
    \item \textit{Build} --- construir o grafo de interferência e categorizar cada vértice como relacionado a \texttt{move} ou não. Um vértice relacionado a \texttt{move} é aquele que é a origem ou o destino de uma instrução de \texttt{move};
    \item \textit{Simplify} --- realizar a remoção dos vértices não-relacionados a \texttt{move}, com grau menor do que o número de cores;
    \item \textit{Coalesce} --- combinar vértices ao estilo de Briggs no grafo reduzido obtido da fase anterior. Como os graus de muitos nós já foram reduzidos pela simplificação, provavelmente haverão muito mais vértices válidos para serem coalescidos do que no grafo de inicial. Após dois vértices $v_i$ e $v_j$ terem sido unidos (e a instrução de \texttt{move} excluída), se $v_{ij}$ não for mais relacionado a \texttt{move}, ele estará apto a ser removido na próxima rodada do \textit{simplify}. Essa etapa e a anterior são repetidas até que restem apenas vértices tal que $grau(v)\geq k$ ou relacionados a \texttt{move}.
    \item \textit{Freeze} --- caso nem \textit{simplify}, nem \textit{coalesce} se aplicarem, um vértice de menor grau é escolhido para tornar-se não-relacionado a \texttt{move}, e apto a sofrer simplificação. Agora, \textit{simplify} e \textit{coalesce} são retomados.
    \item \textit{Select} --- assinalar cores aos vértices, de maneira similar ao método de Briggs.
\end{enumerate}

O \textit{iterated register coalescing} representa o estado da arte da alocação de registradores via coloração de grafos, sendo o algoritmo de referência para os compiladores de produção, bem como os ligados à pesquisa \cite{protzenko:09}. A Figura \ref{fig:iterated-register-coalescing} apresenta um esquema do funcionamento do alocador de George e Appel:

\begin{figure}[hbt]
    \centering
    \begin{tikzpicture}[
        node distance= 1cm and 0.5cm,
        box/.style={draw, rectangle, minimum width=2.1cm, minimum height=1cm, align=center},
        arrow/.style={very thick, ->, >=stealth},
    ]
        \node[box] (build) {\textit{Build}};
        \node[box, right = of build] (simplify) {\textit{Simplify}};
        \node[box, right = of simplify] (coalesce) {\textit{Coalesce}};
        \node[box, right = of coalesce] (freeze) {\textit{Freeze}};
        \node[box, right = of cost] (potspill) {\textit{Potencial spill}};
        \node[box, right = of potspill] (select) {\textit{Select}};

        % \draw[arrow] (simplify.150) .. controls ([yshift=5mm] simplify.150) and ([yshift=5mm] simplify.120) .. (simplify.120);
        \draw[arrow] (build) -- (simplify);
        \draw[arrow] (simplify) -- (coalesce);
        \draw[arrow] (coalesce) -- (freeze);
        \draw[arrow] (freeze) -- (potspill);
        \draw[arrow] (potspill) -- (select);
        \draw[arrow] (freeze.south) .. controls ([yshift=-14mm] freeze.south) and ([yshift=-14mm] simplify.south) .. (simplify.south); 

        \draw[arrow] (coalesce.south) .. controls ([yshift=-7mm] coalesce.south) and ([yshift=-7mm] simplify.300) .. (simplify.300);
        \draw[arrow] (potspill.south) .. controls ([yshift=-21mm] potspill.south) and ([yshift=-21mm] simplify.240) .. (simplify.240);

        \node[box] (spill) at ([yshift=2.5cm] current bounding box.center) {\textit{Spill code}};

        \draw[arrow] (select.north) .. controls ([yshift=10mm] select.north) and ([xshift=4mm] spill.east) .. (spill.east);
        \draw[arrow] (spill.west) .. controls ([xshift=-4mm] spill.west) and ([yshift=10mm] build.north) .. (build.north);
    \end{tikzpicture}
    \caption{Esquema do Iterated Register Coalescing, apresentando a etapa de \textit{freeze}.}
    \label{fig:iterated-register-coalescing}
\end{figure}

\section{Alocação via \textit{Linear Scan}}

Um paradigma de alocação de registradores alternativo à coloração de grafos é o da alocação via \textit{linear scan}, que foi proposta pela primeira vez por Poletto e Sarkar \cite{poletto:99}. Dados os \textit{live ranges} presentes no escopo de uma função, ao invés de construir um grafo de interferência o algoritmo efetua uma única varredura, na ordem de uma enumeração arbitrária da IR, alocando os registradores físicos através de uma estratégia gulosa. 

O algoritmo de \textit{linear scan} é simples, eficiente e produz código comparável ao produzido via coloração de grafos, com a vantagem de propiciar um tempo de compilação consideravelmente mais rápido. Isso pois o algoritmo de \textit{linear scan} apresenta uma complexidade linear, em contrapartida à abordagem por coloração de grafos que tem complexidade quadrática \cite{johansson:01}. Dessa forma, para compiladores onde a velocidade de compilação é uma prioridade, como em compiladores \textit{just-in-time} (JIT) ou interpretadores em tempo real, a alocação via \textit{linear scan} configura-se como a melhor opção.

A técnica de \textit{linear scan} aproxima o conceito de \textit{live range} na forma intervalos vivos, ou \textit{live intervals}. Dada alguma enumeração da representação intermediária, $[i,j]$ é um \textit{live interval} de $v$ se não houverem instruções de número $i'<i$ e $j'>j$, tal que $v$ esteja viva em $i'$ e $j'$. Podem haver subintervalos de $[i,j]$ onde $v$ não está viva, mas eles são ignorados para todos os fins. Os \textit{live intervals} de um programa podem ser facilmente computados por meio de uma única passagem pelo código, e as interferências entre eles são determinadas pela existência de sobreposições entre os intervalos. O Algoritmo \ref{alg:linearscan} apresenta o pseudocódigo do \textit{linear scan}, como mostrado em Poletto e Sarkar \cite{poletto:99}.

O algoritmo consiste em percorrer os intervalos $[i,j]$ em ordem crescente a partir do ponto inicial do intervalo $i$, atribuindo os registradores físicos disponíveis para cada um deles. Uma lista de ativos $A$ é mantida ordenada em ordem crescente dos pontos finais dos intervalos $j$, e armazena os \textit{live intervals} que se sobrepõe com o ponto atual e foram armazenados em registradores. A cada passo, o procedimento varre $A$ removendo os intervalos ``expirados'', cujo ponto final precede o ponto inicial do atual intervalo em análise e o registrador correspondente é marcado como livre para ser alocado. O algoritmo então tenta encontrar um registrador disponível para o atual intervalo e, caso não haja nenhum, \textit{spill} deve ser realizado.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=1.3]{linearscan}
    \caption{Exemplo de um conjunto de cinco \textit{live intervals}. Extraído de Poletto e Sarkar \cite{poletto:99}.}
    \label{fig:linearscan}
\end{figure}

\begin{figure}[hb]
    \centering
    \includegraphics[scale=1.2]{linearscan-comum}
    \caption{Exemplo em pseudocódigo mostrando os \textit{live intervals} no \textit{linear scan} tradicional. Figura extraída de \cite{wimmer:04}.}
    \label{fig:liveintervals-normal}
\end{figure}

Entretanto, o \textit{linear scan} como proposto por Poletto e Sarkar apresenta duas grandes desvantagens. Em primeiro lugar, devido ao seu aspecto guloso, o algoritmo não leva em consideração ``lacunas'' nos \textit{live intervals}, isto é, subintervalos onde o valor da variável não é usado e não precisa ser armazenado. Além disso, uma variável enviada para memória permanecerá em memória durante todo o seu tempo de vida \cite{eisl:16}.

Em 1998, Traub \textit{et al.} \cite{traub:98} propuseram uma versão aprimorada do algoritmo de \textit{linear scan} que realiza a alocação e reescreve o código em uma única varredura no código. No \textit{second-chance binpacking}, o conceito de intervalo é refinado e alcança a mesma precisão dos \textit{live ranges} propriamente ditos, possibilitando aproveitar as lacunas presentes em meio aos \textit{live intervals}. Ao buscar um registrador para uma nova variável, o alocador pode verificar a existência de lacunas nos intervalos previamente alocados e escolher a menor lacuna de tamanho suficiente para comportar o novo \textit{live interval}, reutilizando o mesmo registrador físico. As Figuras \ref{fig:liveintervals-normal} e \ref{fig:liveintervals-binpacking} mostram exemplos do método tradicional e da melhoria de Traub \textit{et al}., respectivamente.

\begin{figure}
    \centering
    \includegraphics[scale=1.2]{linearscan-binpacking}
    \caption{O mesmo exemplo da Figura \ref{fig:liveintervals-normal} com os \textit{live intervals} do \textit{second-chance binpacking}, e a alocação de registradores final. Extraído de Wimmer \cite{wimmer:04}.}
    \label{fig:liveintervals-binpacking}
\end{figure}

\begin{algoritmo}[H]
    \caption{Alocação de registradores via \textit{linear scan}. Adaptado de Poletto e Sarkar \cite{poletto:99}.}
    \begin{algorithmic}
        \Procedure{LinearScanRegisterAllocation}{}
            \State $A \gets \{\}$, ordenado em ordem crescente de fim
            \ForAll{intervalo $i \in I$}
                \State \Call{ExpirarIntervalos} {i}
                \If{$|A|=R$}
                    \State \Call{Spill} {i}
                \Else
                    \State $\mathit{alocados}[i] \gets$ um registrador removido da lista de \textit{livres}
                \EndIf
            \EndFor
        \EndProcedure
        
        \Function{ExpirarIntervalos}{i}
            \ForAll{intervalo $a \in A$}
                \If{$\mathit{fim}[a] \geq \textit{inicio}[i]$}
                    \State \Return
                \EndIf
                \State $A \gets A-\{a\}$
                \State $\mathit{livres} \gets \textit{livres} \cup \{\textit{alocados}[a]\}$
            \EndFor
        \EndFunction
        
        \Function{Spill}{i}
            \State $\mathit{spill} \gets$ último intervalo em $A$
            \If{$\mathit{fim}[\textit{spill}] > \textit{fim}[i]$}
                \State $\mathit{alocados}[i] \gets \textit{alocados}[\textit{spill}]$
                \State $\mathit{local}[\textit{spill}] \gets $ lugar na pilha
                \State $A \gets A - \{\textit{spill}\}$
                \State $A \gets A \cup \{i\}$
            \Else
                \State $\mathit{local}[\textit{i}] \gets $ lugar na pilha
            \EndIf
        \EndFunction
    \end{algorithmic}
    \label{alg:linearscan}
\end{algoritmo}

\section{Alocação via PBQP}

Em 2002, Scholz e Eckstein \cite{scholz:02} propuseram uma abordagem inovadora para a alocação de registradores valendo-se do PBQP (\textit{Partitioned Boolean Quadratic Optimization Problem}), um problema de otimização que consiste em modelar conjuntos de escolhas como equações booleanas, cada qual com uma lista de custos associados e visando encontrar a sequência de escolhas que produza o resultado com menor custo possível. Esse método de alocação consegue efetivamente combinar as tarefas do alocador e representava as peculiaridades de arquiteturas irregulares em um único problema.

Para cada registrador simbólico, o alocador deve decidir se o armazena em um dos registradores $r_1$, $r_2$, $\ldots$, $r_k$, sendo $k$ o número de registradores físicos, ou se o envia para a memória principal. Essa decisão é expressa na forma de uma equação formada por uma soma de variáveis booleanas. Uma das variáveis booleanas representa a decisão de se fazer \textit{spill} do registrador virtual, enquanto as variáveis booleanas restantes representam as decisões de se alocar algum registrador da CPU à variável. A Fórmula \ref{eq:equacao-pbqp} expressa a equação booleana, onde $x_{\textit{spill}}\in \{0,1\}$ representa a decisão de \textit{spill} e $x_{i}\in \{0,1\}$ simboliza a alocação de algum dos $k$ registradores.

\begin{equation}
    x_{\textit{spill}} + x_{1} + x_{2} + \ldots + x_{k} = 1
    \label{eq:equacao-pbqp}
\end{equation}

Como a Equação \ref{eq:equacao-pbqp} é linear, ela pode ser representada na forma de um vetor booleano $\Vec{x_v}$. De maneira análoga, os custos de cada alocação $a$ do conjunto das possibilidades de alocação $A$, associada aos índices de $\Vec{x_v}$, compõe o vetor de custo $\Vec{c_v}$. Nesse caso, a atribuição de um registrador físico para o registrador virtual $v$ corresponde a um índice $\phi_a$ de $\Vec{x_v}$ cuja variável booleana correspondente é igual a 1, e $f_v$ é a função do custo de alocação de $v$ dentre o conjunto $F_v$, que simboliza os custos de se alocar a variável a cada um dos registradores disponíveis. A Fórmula \ref{eq:vetor-pbqp} apresenta a definição matemática de $\Vec{c_v}$:

\begin{equation}
    \forall a \in A : \Vec{c_v}({\phi}_a)=\sum_{\mathclap{f_v \in F_v}}f_v(a).
    \label{eq:vetor-pbqp}
\end{equation}

Sendo assim, tem-se que cada registrador virtual tem a si associado um vetor de custos na forma $\Vec{c_v} = [110, 0, 4, \infty, \ldots, \infty]^T$. Nesse exemplo, temos que o primeiro índice é o custo de \textit{spill} da variável; os dois índices seguintes são o custo de alocação para dois registradores físicos hipotéticos. Os índices subsequentes, com custo infinito, representam possibilidades de alocação não permitidas por alguma restrição da arquitetura ou porque já estão ocupadas.

Se dois registradores virtuais $u$ e $v$ forem dependentes entre si devido a alguma interferência nos \textit{live ranges}, estiverem conectadas por uma instrução de cópia ou constituírem um par ditado pela arquitetura, o custo de alocação é expresso pela forma quadrática $\Vec{x_u}C_{uv}\Vec{x_v}^T$, definido de acordo com a Fórmula \ref{eq:formula-matriz-pbqp}. De maneira análoga, $a_u, a_v \in A$ representam um par de alocações de registradores para $u$ e $v$ respectivamente, e ambos os índices $\phi_{a_u},\phi_{a_v}$ dos vetores de custo individuais de cada variável são levados em conta na obtenção do custo combinado $C_{uv}$. Por isso, o conjunto dos custos $C_{uv}$ assume a forma da Matriz \ref{eq:matriz-pbqp}, onde os índices de linha e coluna estão associados às decisões individuais em $u$ e $v$.

\begin{equation}
        \forall a_u, a_v \in A : C_{uv}(\phi_{a_u},\phi_{a_v}) = \sum_{\mathclap{f_{uv} \in F_{uv}}} f_{uv}(a_u,a_v)
        \label{eq:formula-matriz-pbqp}
    \end{equation}

\begin{equation}
        C_{uv} = \begin{bmatrix}
        c_{ij}
        \end{bmatrix} = \begin{bmatrix}
            0 & 0 & \ldots & 0 \\
            0 & \infty & \ddots & \vdots \\
            \vdots & \ddots & \ddots & 0 \\
            0 & \ldots & 0 & \infty
        \end{bmatrix}
        \label{eq:matriz-pbqp}
\end{equation}

Sendo assim, a tarefa de alocação é expressa na forma de um problema de particionamento quadrático, que consiste em encontrar o esquema de alocação que minimize o resultado da Fórmula \ref{eq:pbqp}.

\begin{equation}
    \text{min }f = \sum_{\mathclap{1 \leq u < v \leq k}} \Vec{x}_u C_{uv} \Vec{x}_v^T + \sum_{\mathclap{1 \leq u \leq k}} \Vec{c}_u \Vec{x}_u^T.
    \label{eq:pbqp}
\end{equation}

Na Fórmula \ref{eq:pbqp}, os índices $u$ e $v$ representam pares de registradores virtuais e $k$ é o número de registradores virtuais. Devido às propriedades simétricas das formas quadráticas, o resultado da função é uma soma triangular \footnote{Soma triangular, ou número triangular, é um número dado pela série $\sum_{k=1}^n k=1+2+3+\ldots+n=\frac{(n^2+n)}{2}$ \cite{hoggatt:74}.}. Observa-se que existe pelo menos uma solução com custo finito, desde que os custos de \textit{spill} sejam finitos. Isto se deve ao fato de que todos as variáveis podem sofrer \textit{spill}, embora não seja uma boa solução.

Ainda que o problema possa ser expresso formalmente, uma modelagem baseada em grafos é mais intuitiva. Nesse contexto, cada vértice do grafo possui um vetor de escolha associado, que atribui a cada alternativa seu custo de execução, e para cada nó apenas uma alternativa pode ser selecionada. As interdependências são modeladas por arestas direcionadas com uma matriz associada, que contém os custos das combinações de alternativas. A Figura \ref{fig:9} mostra um exemplo de representação de um problema PBQP via grafo. Cada vértice u, v e w possui três alternativas que representam suas cores possíveis. Devido às matrizes de arestas, cada solução possível deve selecionar cores diferentes para nós adjacentes e, portanto, representa uma 3-coloração válida \cite{buchwald:11}.

\begin{figure}
    \centering
    \includegraphics[scale=1.5]{pbqp}
    \caption{Grafo de resolução do PBQP considerando 3 registradores virtuais. Extraído de Buchwald \textit{et al} \cite{buchwald:11}}
    \label{fig:9}
\end{figure}

O PBQP é um problema NP-completo, de maneira similar à coloração de grafos. No entanto, soluções quase-ótimas podem ser obtidas através de técnicas como programação dinâmica e a aplicação de heurísticas de simplificação, que permitem reduzir uma instância do problema de tal modo que a melhor resolução torne-se trivial. Ao retropropagar as reduções, a seleção da instância menor pode ser estendida para uma seleção da instância original do PBQP. Originalmente, foram propostas quatro reduções \cite{buchwald:10, eckstein:03}:
\begin{enumerate}
    \item \textit{RE} --- remoção de arestas independentes, possuindo uma matriz de custos que pode ser decomposta em dois vetores $\Vec{u}$ e $\Vec{v}$, ou seja, cada entrada da matriz $c_{ij}$ tem custos $u_i$ + $v_j$. Essas arestas podem ser removidas ao se somar $\Vec{u}$ e $\Vec{v}$ aos vetores de custo dos vértices de origem e de destino, respectivamente. Se isto produzir custos vetoriais infinitos, a alternativa correspondente (incluindo linhas/colunas da matriz) é eliminada;

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=1.3, node/.style={draw,circle,scale=1.3}]
            \node[node] (u1) {$u$};
            \node[node, right = of u1] (v1) {$v$};
            \coordinate[right = of v1] (a);
            \coordinate[right = of a] (b);
            \node[node, right = of b] (u2) {$u$};
            \node[node, right = of u2] (v2) {$v$};
    
            \draw[->, ultra thick, red] (u1) -- (v1);
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (a) -- (b);
        \end{tikzpicture}
    \end{figure}

    \item \textit{RI} --- remoção de vértices de grau um, somando os custos no vértice adjacente;

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=1.3, node/.style={draw,circle,scale=1.3}]
            \node[node] (u1) {$u$};
            \node[node, right = of u1, red] (v1) {$v$};
            \coordinate[right = of v1] (a);
            \coordinate[right = of a] (b);
            
            \node[node, right = of b] (u2) {$v$};
    
            \draw[->, ultra thick, black] (u1) -- (v1);
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (a) -- (b);
        \end{tikzpicture}
    \end{figure}

    \item \textit{RII} --- remoção de vértices de grau dois, após os custos serem contabilizados na matriz de custos da nova aresta entre os dois vizinhos. Se necessário, a aresta é criada primeiro;

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=1.3, node/.style={draw,circle,scale=1.3}]
            \node[node] (u1) {$u$};
            \node[node, right = of u1, red] (v1) {$v$};
            \node[node, right = of v1] (w1) {$w$};
            \draw[->, ultra thick, black] (u1) -- (v1);
            \draw[->, ultra thick, black] (v1) -- (w1);
            
            \coordinate[right = of w1] (a);
            \coordinate[right = of a] (b);

            \node[node, right = of b] (u2) {$u$};
            \coordinate[right = of u2] (c);
            \node[node, right = of c] (w2) {$w$};
            \draw[->, ultra thick, black] (u2) -- (w2);
            
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (a) -- (b);
        \end{tikzpicture}
    \end{figure}

    \item \textit{RN} --- remoção de vértices de grau três ou maior. Dado um vértice $u$, é escolhido um mínimo local e os custos de $u$ são distribuídos entre seus vizinhos. Em seguida, $u$ é removido e as arestas são removidas usando \textit{RE}.

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=1.3, node/.style={draw,circle,scale=1.3}]
            \node[node, red] (u) {$u$};
            \node[node, above = of u] (y1) {$y$};
            \node[node, below left = of u] (x1) {$x$};
            \node[node, below right = of u] (z1) {$z$};
            \draw[->, ultra thick, black] (x1) -- (u);
            \draw[->, ultra thick, black] (y1) -- (u);
            \draw[->, ultra thick, black] (z1) -- (u);
            
            \coordinate[above right = of z1] (a);
            \coordinate[right = of a] (b);
            \node[node, below right = of b] (x2) {$x$};
            \node[node, above right = of x2, white] (u2) {};

            \node[node, above = of u2] (y2) {$y$};
            \node[node, below right = of u2] (z2) {$z$};
            
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (a) -- (b);
        \end{tikzpicture}
    \end{figure}
\end{enumerate}

As reduções \textit{RE}, \textit{RI}, e \textit{RII} produzem subdivisões da instância original de igual custo mínimo, permitindo estender a seleção dos problemas menores para o problema original sem comprometer a qualidade da solução. Se o grafo inteiro puder ser reduzido dessa maneira, então é possível encontrar uma solução ótima para dada instância do problema. Se \textit{RN} for aplicada, no entanto, as subpartes produzidas perdem a precisão de representação do problema e a solução final obtida torna-se quase-ótima, onde a proximidade de uma hipotética solução ótima é garantida através da heurística de escolha do mínimo local como alternativa.

Hames e Scholz \cite{hames:06} propuseram, em 2006, uma heurística alternativa para a redução \textit{RN} que elimina a escolha de uma alternativa na etapa de redução, efetivamente a postergando para a fase de retropropagação das soluções. Além disso, eles introduziram um abordagem \textit{branch-and-bound} que consiste em utilizar de um limiar para dividir as possíveis combinações de escolhas, de tal modo que as combinações que certamente não são ótimas são descartadas e nunca são avaliadas pelo alocador. Essas heurísticas garantem resolução em tempo linear, e as reduções tornam a alocação via PBQP especialmente poderosa em instâncias que produzem grafos de interferência esparsos, pois permitem a alocação de maneira trivial.

\chapter{Minimização de \textit{Spill Code}}

Mesmo com a utilização de algoritmos refinados de alocação, em vários casos a introdução de \textit{spill code} no código resultante é factualmente inevitável. Sendo assim, um bom alocador deve produzir uma alocação visando minimizar o tráfego de dados entre a memória principal e o processador, devido ao grande atraso provocado pela execução de instruções de acesso à memória. Essas operações são responsáveis pela maior parte do gasto energético em sistemas computacionais \cite{verma:06}, e a alocação de registradores pode impactar o tempo de execução de um programa em até 250\% \cite{pereira:08}.

Dentre os problemas enfrentados pelos desenvolvedores de compiladores, há a notável tarefa de se decidir qual registrador virtual será enviado para a memória. A escolha deve ser tomada de modo a reduzir a pressão de registradores nos pontos problemáticos do código, preferencialmente tornando-o inteiramente alocável e resolvendo o problema com o \textit{spill} de uma única variável. No entanto, a escolha de uma variável frequentemente acessada, que está dentro de um laço de repetição ou é usada como controle, pode acidentalmente produzir muito mais acessos à memória no programa \cite{chaitin:82, bernstein:89}.

Além disso, há espaço para diferentes análises na tarefa de se estimar custos de \textit{spill}. Diferentes métodos de se definir o custo das operações de acesso à memória e calcular o custo associado à escolha de cada variável são possíveis, e podem produzir resultados diferentes considerando a especificidade arquitetura-alvo. Sendo assim, os desenvolvedores de compiladores dependem de experimentação e ``tentativa e erro'' para ajustar suas heurísticas de alocação \cite{amarasinghe:03}.

\section{Heurísticas de Chaitin}

A proposta inicial do primeiro alocador via coloração de grafos, feita por Chaitin \textit{et al.} em 1981, não continha heurísticas significativas para otimizar a introdução de \textit{spill code}. Inicialmente, a prioridade de escolha para a realização de \textit{spill} era dada às variáveis denominadas \textit{pass-through} --- isto é, que estão vivas na entrada dos blocos básicos e não são usadas nem redefinidas posteriormente. Instruções de \texttt{store} eram inseridas após toda redefinição do \textit{live range} escolhido, e os \texttt{loads} eram necessários antes de qualquer uso \cite{chaitin:81}.

Sendo assim, em um trabalho posterior de 1982 \cite{chaitin:82}, Chaitin formalizou heurísticas para a tomada de decisões de \textit{spill} que almejavam reduzir a quantidade de acessos a memória em tempo de execução. O custo de \textit{spill} de um registrador virtual é definido como o aumento no tempo de execução caso ele resida em memória, que corresponde ao número de pontos de definição mais o número de usos do valor. Por suas vezes, as definições e usos são ponderados levando em conta suas frequências estimadas de execução.

O custo de \textit{spill} associado a um \textit{live range} $v$ no alocador de Chaitin é dado pela Fórmula \ref{chaitin-custo}, onde $i$ é uma instrução contida no conjunto de instruções da IR do programa $I$, que manipula $v$ através de um uso ou uma redefinição, representados respectivamente pelos predicados $\mathit{use}_v(i)$ e $\mathit{def}_v(i)$. A função $\mathit{profundidade} (i)$ expressa o nível de aninhamento de $i$ dentro de laços de repetição. 

\begin{equation}
    \textit{custo}(v) = \sum_{\mathclap{\substack{i \in I\\\textit{use}_v(i) \lor \textit{def}_v(i)}}} 10 ^ {\textit{profundidade}(i)}
    \label{chaitin-custo}
\end{equation}

Os custos são computados quando, durante a etapa de \textit{simplify}, não são encontrados mais vértices aptos a serem removidos do grafo de interferência e o algoritmo trava. Em seguida, o alocador define as prioridades para a escolha de qual variável sofrerá \textit{spill} utilizando a Fórmula \ref{chaitin-prioridade}. Para cada \textit{live range}, o custo é dividido pelo grau do vértice correspondente no grafo e o vértice com menor valor ponderado é escolhido para sofrer \textit{spill} em todo o código \cite{bernstein:89}.

\begin{equation}
    h(v) = \frac{\textit{custo}(v)}{\textit{grau}(v)}
    \label{chaitin-prioridade}
\end{equation}

Chaitin \cite{chaitin:82} ainda introduziu o conceito de proximidade entre instruções: duas instruções são ditas próximas se nenhum \textit{live range} for eliminado entre elas e, consequentemente, nenhum registrador for liberado para alocação nesse intervalo. Esse princípio fundamenta um conjunto de três diretrizes que buscam evitar a inserção de \textit{reloads} desnecessários no código. São elas:
\begin{enumerate}
    \item Se uma definição e um uso são próximos, não é necessário adicionar um \texttt{load} antes do uso. Isso ocorre porque, como não foram disponibilizados novos registradores entre as instruções, o registrador da segunda instrução está disponível para a primeira. Sendo assim, é possível alocar o mesmo registrador para as duas utilizações;
    \item Se duas instruções de uso são próximas, é necessário introduzir um \texttt{load} somente antes do primeiro uso. De maneira análoga à diretriz anterior, o mesmo registrador pode ser reaproveitado na segunda instrução;
    \item Se a primeira definição e o último uso de um \textit{live range} são próximos, então o custo de \textit{spill} do registrador virtual é considerado infinito. Como nenhum registrador é liberado, enviar a variável para memória não tornará o programa colorível.
\end{enumerate}
    
\section{Heurísticas de Bernstein}

Em um trabalho de 1989, Bernstein \textit{et al.} \cite{bernstein:89} pontuaram uma série de problemas com o alocador de Chaitin. Em primeiro lugar, a heurística empregada na decisão de \textit{spill} pode não ser a mais eficiente em todas as instâncias de alocação. Além disso, o alocador de Chaitin insere instruções \texttt{store}/\texttt{load} desnecessariamente em todos os pontos do antigo \textit{live range}, sendo que elas podem somente ser necessárias em pontos de grande pressão de registradores. 

Sendo assim, o trabalho trouxe algumas técnicas e novas heurísticas visando expandir as contribuições de Chaitin. Essas melhorias se mostraram capazes de reduzir a quantidade de código \textit{spill}, na média, em 6\% e 12\%, chegando até 30\% em alguns casos.

\subsection{\textit{Best-of-three}}

Bernstein \textit{et al.} notaram que, a respeito da heurística de decisão de \textit{spill}, não se pode fazer uma afirmação absoluta sobre o desempenho de uma função heurística simples em relação a outra para todos os programas. Ao contrário, diferentes instâncias de problemas de alocação podem exigir estratégias distintas para a obtenção de melhores resultados. Eles propuseram comparar o desempenho médio de diferentes fórmulas, mantendo em mãos um seleto número funções heurísticas que vislumbrem as diferentes causas da pressão de registradores, e escolhendo a melhor delas para tomar as decisões de \textit{spill}.

A heurística $h_1$ (Fórmula \ref{eq:bernstein-1}) tem em vista a estratégia original de Chaitin, que consiste em escolher um vértice com baixo custo e alto grau. Realizar \textit{spill} de uma variável com alto grau reduz o grau de muitos outros vértices no grafo de interferência, tornando mais provável que outros vértices se tornem desobstruídos.

\begin{equation}
    h_1(v) = \frac{\textit{custo}(v)}{\textit{grau}(v)^2}
    \label{eq:bernstein-1}
\end{equation}

Alternativamente, a abordagem escolhida pode ser a de se fazer \textit{spill} do registrador virtual que exerça a maior pressão de registradores sobre o código. Sendo assim, é introduzido o conceito de área de uma variável, computado através da Fórmula \ref{bernstein-area}:
\begin{equation}
    \textit{área}(v) = \sum_{\mathclap{\substack{i \in I\\v\text{ vivo em }i}}} 5 ^ {\textit{profundidade}(i)} \textit{largura}(i)
    \label{bernstein-area}
\end{equation}
onde $\mathit{largura}(i)$ é o número de variáveis vivas no momento de execução da instrução $i$. De maneira intuitiva, $\mathit{área}(v)$ expressa o impacto de $v$ para a pressão de registradores global. A escolha de uma variável com alta área causa uma redução considerável na pressão em todo o programa, e facilita a coloração. As heurísticas seguintes $h_2$ e $h_3$ (Fórmulas \ref{eq:bernstein-2} e \ref{eq:bernstein-3}) se fundamentam nesse princípio.

\begin{equation}
    h_2(v) = \frac{\mathit{custo}(v)}
                  {\textit{área}(v)\mathit{grau}(v)}
    \label{eq:bernstein-2}
\end{equation}

\begin{equation}
    h_3(v) = \frac{\mathit{custo}(v)}
                  {\mathit{área}(v) \mathit{grau}(v) ^ 2}
    \label{eq:bernstein-3}
\end{equation}

O algoritmo proposto por Bernstein \textit{et al.} efetua efetua a coloração do grafo de interferência múltiplas vezes, para cada heurística $h_i$ disponível. O resultado final escolhido é o da heurística que produza o menor custo total de \textit{spill}. Essa técnica, apelidada de ``\textit{best-of-three}'', superou as abordagens anteriores consideravelmente, sob penalidade de um tempo de compilação ligeiramente maior.

\subsection{\textit{Coloração gulosa}}

Bernstein \textit{et al.} \cite{bernstein:89} também introduziram heurísticas de coloração que se baseiam em adotar uma estratégia local para cada região do programa. É sabido que o grafo de interferência pode conter diversos subgrafos com diferentes características, sendo que alguns deles podem ser coloridos em tempo polinomial \cite{golumbic:04, dagan:88}. Dessa maneira, diferentes formas de coloração podem ser adotadas em diferentes porções do código, e os resultados combinados para compor a alocação final.

O algoritmo de coloração de por Bernstein \textit{et al.} realiza a etapa de \textit{simplify} removendo sempre o vértice apto de maior grau. Logo, na etapa de \textit{select}, os registradores são alocados em ordem crescente de grau para cada \textit{live range}. Ademais, após a $k$-colorabilidade do grafo de interferência ter sido assegurada, um critério secundário pode usado para colori-lo com, geralmente, menos cores do que em uma atribuição aleatória. Em certas situações, isso pode melhorar o código resultante, como:

\begin{itemize}
    \item A alocação produziu \textit{spills} a mais, e torna-se possível colorir o grafo com menos do que $k$ cores. Nesse caso, as $k - n$ decisões de \textit{spill} mais custosas da iteração anterior podem ser desfeitas;
    \item Pequenos procedimentos chamados frequentemente, onde uma utilização de registradores econômica pode reduzir o \textit{overhead} das chamadas;
    \item Expansões \textit{inline} de funções, onde a decisão de expandir ou não é influenciada pela quantidade de registradores utilizados na sub-rotina.
\end{itemize}

\subsection{\textit{Cleaning}}

Bernstein \textit{et al.} \cite{bernstein:89} resolveram o problema da inserção desnecessária de instruções \texttt{store}/\texttt{load} através da técnica denominada pelos autores como ``\textit{cleaning}'', ou limpeza. Esse método consiste em, quando uma variável for enviada para a memória, inserir somente uma instrução \texttt{store} e um \texttt{load} por bloco básico. Ao examinar um bloco em busca de valores que sofreram \textit{spill}, os acessos à memória são introduzidos apenas no primeiro uso ou definição do \textit{live range}. Em seguida, a variável é renomeada em cada bloco básico em que é usada, fragmentando o tempo de vida original.

Os autores observaram que o \textit{cleaning} é bem sucedido em reduzir o número total de instruções de acesso à memória, especialmente nas primeiras duas iterações de coloração/\textit{spill}, e quando nenhuma restrição é imposta à profundidade dos blocos básicos nos quais a limpeza é realizada ou aos registradores para os quais a limpeza é aplicada. O pseudocódigo mostrando o fluxo de execução da técnica de Bernstein \textit{et al.} com a realização do \textit{cleaning} encontra-se no Algoritmo \ref{alg:bernstein}.

\begin{algoritmo}[hb]
    \caption{Algoritmo de coloração utilizando \textit{best-of-three}. Extraído de Bernstein \textit{et al.} \cite{bernstein:89}}
    \begin{algorithmic}
        \Require $R$: conjunto de registradores físicos, $G$: grafo de interferência, $S_i$: lista de \textit{spill} associada à heurística $h_i$, $h_i$: heurística.
        \Procedure{ColorAndSpill}{}
            \ForAll{método heurístico $h_i$}
                \While{$G$ não é vazio}{}
                    \If{existe um $v$ no grafo $G$ tal que $\mathit{grau}(v) < |R|$}
                        \State escolha o $v$ com maior grau (tal que $\mathit{grau}(v) < |R|$)
                        \State $G \gets G - \{v\}$
                    \Else
                        \State escolha um $v$ tal que $\text{min }h_i(v)$
                        \State $S_i \gets S_i \cup \{v\}$
                        \State $G \gets G - \{v\}$
                    \EndIf
                \EndWhile
                \State restaure $G$
            \EndFor

            \State escolha a heurística $h_i$ com o menor $\mathit{custo}(S_i)$
            \If{nenhum vértice tiver sofrido \textit{spill}}
                \State pinte os vértices em ordem reversa da remoção de $G$
            \Else
                \ForAll{vértice $v \in S_i$}
                    \Call{Spill}{v}
                \EndFor
                \State realize \textit{``cleaning''} nos blocos básicos
                \State reconstrua o grafo $G$
            \EndIf
        \EndProcedure
    \end{algorithmic}
    \label{alg:bernstein}
\end{algoritmo}

\section{\textit{Spilling} por Região de Interferência}

Em 1997, Bergner \textit{et al.} publicaram um artigo \cite{bergner:97} pontuando que as heurísticas prévias ainda produziam \textit{spill} code desnecessariamente, pois as instruções de acesso à memória eram inseridas ao longo de todo o tempo de vida que era escolhido para \textit{spill}. Em resposta a esse problema, Bergner \textit{et al.} introduziu o conceito de \textit{spilling} por região de interferência, que consistia em limitar as alterações no código somente às regiões de sobreposição entre os \textit{live ranges}, nos pontos de alta pressão de registradores.

Nessa abordagem, uma região de interferência entre dois registradores virtuais é dita como a porção do programa onde ambos estão vivos simultaneamente, e elas são diretamente representadas no grafo de interferência na forma das arestas. Em adição às técnicas de minimização de \textit{spill code} propostas por Chaitin \cite{chaitin:81}, Bernstein \cite{bernstein:89} e Briggs \cite{briggs2:92}, o alocador de Bergner limita a introdução de \textit{reloads} somente aos usos da variável dentro da região de interferência. No caso em que o \textit{live range} é utilizado novamente após a região de interferência, deve-se introduzir um \textit{reload} adicional para recarregar o valor de volta para um registrador físico.

\begin{figure}[hbt]
    \centering
    \adjustbox{center}{\begin{lstlisting}
A = input();
B = A + 1;
if (A) {
    C = A + 2;
    B = A + C;
    if (C) {
        B = B + C;
        C = B + C;
    }
    A = B + C;
}
D = A + B;
    \end{lstlisting}}
    \caption{Exemplo de programa em pseudocódigo extraído de Bergner \textit{et al.} \cite{bergner:97}.}
    \label{fig:bergner-codigo}
\end{figure}

\begin{figure}[hbt]
        \centering
        \begin{tikzpicture}[scale=2, node/.style={draw,circle, scale=1.2}]
            \node[node] (A) {$A$};
            \node[left = 1mm of A] {$8$};
            \node[node, right = 25mm of A] (B) {$B$};
            \node[right = 1mm of B] {$12$};
            \node[node, below = 25mm of A] (C) {$C$};
            \node[left = 1mm of C] {$12$};
            \node[node, right = 25mm of C] (D) {$D$};
            \node[right = 1mm of D] {$\infty$};

            \draw[black, thick] (A) -- (B);
            \draw[black, thick] (A) -- (C);
            \draw[black, thick] (C) -- (B);
        \end{tikzpicture}
        \caption{Grafo de interferência correspondente ao código da Figura \ref{fig:bergner-codigo}, com os custos de \textit{spill} indicados.}
        \label{fig:bergner-grafo}
    \end{figure}

Para escolher quais regiões de interferência sofrerão \textit{spill}, a estratégia desenvolvida por Bergner é aplicada durante a etapa de \textit{select} de um alocador ao estilo de Briggs, durante a reintrodução dos vértices no grafo e concomitante alocação de cores. Ao se tentar reintroduzir um vértice $v$ candidato a \textit{spill} --- o que não será inteiramente possível devido ao número de interferências de $v$, suas arestas são agrupadas em conjuntos, cada conjunto contendo as arestas que se conectam a vértices de uma mesma cor. O alocador deve então tentar colorir $v$, não inserindo no grafo as arestas do conjunto cuja cor já está atribuída a algum dos seus vizinhos. 

O custo de se fazer \textit{spill} de $v$ em cada região de interferência é calculado levando em conta a quantidade estimada de instruções \texttt{store}/\texttt{load} que serão introduzidas no código, e a cor selecionada para o vértice candidato deve ser a que minimize o total desse custo. Uma vez que a cor é definida, as regiões de interferência cujas arestas correspondentes não puderam ser inseridas no grafo são escolhidas para sofrerem \textit{spill}. A Figura \ref{fig:bergner-grafo-col} demonstra esse processo ao tentar colorir o grafo da Figura \ref{fig:bergner-grafo}, onde o vértice candidato $A$ recebe a mesma cor de $C$, impedindo que a aresta $AC$ seja introduzida no grafo. Ela é então descartada, e $A$ sofrerá \textit{spill} na região de interferência entre $A$ e $C$.

\begin{figure}[hbt]
    \centering
    \begin{subfigure}{0.44\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}[scale=2, node/.style={draw,circle, scale=1.2}]
            \node[node] (A) {$A$};
            \node[node, right = 25mm of A, fill=yellow] (B) {$B$};
            \node[node, below = 25mm of A, fill=red] (C) {$C$};
            \node[node, right = 25mm of C, fill=yellow] (D) {$D$};

            \draw[black, thick, dotted] (A) -- (B);
            \draw[black, thick, dotted] (A) -- (C);
            \draw[black, thick] (C) -- (B);
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{0.1\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (0,5) -- (1,5);
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{0.44\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}[scale=2, node/.style={draw,circle, scale=1.2}]
            \node[node, fill=red] (A) {$A$};
            \node[node, right = 25mm of A, fill=yellow] (B) {$B$};
            \node[node, below = 25mm of A, fill=red] (C) {$C$};
            \node[node, right = 25mm of C, fill=yellow] (D) {$D$};

            \draw[black, thick] (A) -- (B);
            \draw[black, thick] (C) -- (B);
        \end{tikzpicture}}
    \end{subfigure}
    \caption{Coloração do exemplo da Figura \ref{fig:bergner-grafo}, considerando a estratégia de \textit{spilling} por região de interferência. Adaptado de Bergner \textit{et al.} \cite{bergner:97}.}
    \label{fig:bergner-grafo-col}
\end{figure}

A comparação entre o código gerado pela técnica tradicional e o pelo \textit{spilling} por região de interferência é exibida na Figura \ref{fig:bergner-comparacao}. A estratégia de Bergner \textit{et al.} apresentou altas taxas de sucesso em experimentos, conquistando uma redução média de 33,6\% no número de instruções de acesso a memória executadas dinamicamente, atingindo a faixa de 75\% em alguns casos \cite{bergner:97}. Essa técnica superou de longe as heurísticas anteriores, e representou um avanço significativo na minimização de \textit{spill code}. 

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \adjustbox{center}{\begin{lstlisting}[mathescape=true]
A = input();
store A;
B = A + 1;
if (A) {
    load $\texttt{A}_1$;
    C = $\texttt{A}_1$ + 2;
    B = $\texttt{A}_1$ + C;
    if (C) {
        B = B + C;
        C = B + C;
    }
    $\texttt{A}_2$ = B + C;
    store $\texttt{A}_2$;
}
load $\texttt{A}_3$;
D = A + B;
        \end{lstlisting}}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \adjustbox{center}{\begin{lstlisting}[mathescape=true]
A = input();
store A;
B = A + 1;
if (A) {
    load $\texttt{A}_1$;
    C = $\texttt{A}_1$ + 2;
    B = $\texttt{A}_1$ + C;
    if (C) {
        B = B + C;
        C = B + C;
    }
    A = B + C;
    
}

D = A + B;
        \end{lstlisting}}
    \end{subfigure}
    \caption{Comparação entre os resultados da técnica tradicional e do \textit{spilling} por região de interferência. Na esquerda, \texttt{A} sofre \textit{spill} em todo o código, enquanto na direita a inserção de \textit{spill code} ocorre somente na interferência entre \texttt{A} e \texttt{C}. Adaptado de Bergner \textit{et al.} \cite{bergner:97}.}
    \label{fig:bergner-comparacao}
\end{figure}

\section{Rematerialização}

Em seu trabalho de 1982, Chaitin \textit{et al.} \cite{chaitin:82} já haviam demonstrado que é preferível inserir instruções para recalcular certos valores ao invés de armazená-los em memória, devido ao custo mais baixo de fazê-lo. Essa técnica foi denominada ``\textit{rematerialization}'', ou rematerialização, e representa uma alternativa à geração de \textit{spill code} em situações onde a pressão de registradores ultrapassa o número de registradores físicos disponíveis. Posteriormente, Briggs \textit{et al.} \cite{briggs2:92} refinaram essa técnica, introduzindo novos conceitos e propondo uma metodologia que permite uma otimização mais profunda.

Chaitin \textit{et al.} mostraram que certos valores podem ser recalculados com uma única instrução adicional, caso os operandos necessários estejam sempre disponíveis. Eles denominaram esses casos excepcionais como valores \textit{``never-killed''}, e argumentaram que é mais barato recomputar tais valores do que armazená-los e constantemente acessar a memória para recuperá-los. Na prática, boas oportunidades para a rematerialização incluem \texttt{loads} imediatos de constantes e o cálculo de endereços de memória, com ou sem \textit{offset}. Entretanto, o alocador de Chaitin só pode rematerializar \textit{live ranges} que assumem um único valor ao longo de toda sua extensão, não sendo capaz de lidar com casos mais complexos.

Sendo assim, em 1992 Briggs \textit{et al.} \cite{briggs2:92} expandiram a técnica de Chaitin para tratar \textit{live ranges} multivalorados. Sua abordagem consistia em dividir os tempos de vida para cada valor que assumem ao longo da execução de um programa, efetivamente convertendo a representação intermediária para a forma SSA (\textit{static single-assignment}). Na forma SSA, cada variável é definida uma única vez antes de ser obrigatoriamente usada, e por isso possui apenas um valor ao longo do seu tempo de vida. 

No processo de conversão para a forma SSA, os \textit{live ranges} dão origem vários tempos de vida menores definidos uma única vez, a partir de um valor simples ou uma função-$\phi$ --- artifício que representa a utilização de um dentre múltiplos valores possíveis em tempo de execução. A Figura \ref{fig:ssa} apresenta um exemplo de código nas formas tradicional e SSA, onde a variável \texttt{w} é definida a partir de \texttt{y}, que recebe valores diferentes em cada caso de uma ramificação condicional. Sendo assim, deve ser criada uma nova variável $\texttt{y}_3$ que pode receber tanto o valor de $\texttt{y}_1$ quanto $\texttt{y}_2$, a depender de qual bloco condicional será acessado em tempo de execução.

\begin{figure}[hbt]
    \centering
    \begin{subfigure}{0.40\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}[CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=5mm, align=center}]

            \node[CFG] (B0) {\texttt{x := 5}\\
                             \texttt{x := x-3}\\
                             \texttt{if x<3}};
    
            \node[CFG, below right = 12.8mm and 0.2mm of B0] (B1) 
                {\texttt{y := x-3}};
            \node[CFG, below left = 10mm and 0.2mm of B0] (B2) 
                {\texttt{y := x*2}\\
                 \texttt{w := y}};
            \node[CFG, below right = 10mm and 0.2mm of B2] (B3) 
                {\texttt{w := x-y}\\
                 \texttt{z := x+y}};

            \draw[-latex, black, very thick] (B0.south) -- (B1.north) {};
            \draw[-latex, black, very thick] (B0.south) -- (B2.north) {};
            \draw[-latex, black, very thick] (B1.south) -- (B3.north) {};
            \draw[-latex, black, very thick] (B2.south) -- (B3.north) {};
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{0.09\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}
            \draw[-{Triangle[width=18pt,length=8pt]}, line width=10pt] (0,5) -- (1,5);
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{0.40\textwidth}
        \centering
        \adjustbox{valign=c}{\begin{tikzpicture}[CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=5mm, align=center}]

            \node[CFG] (B0) {$\texttt{x}_1\ \texttt{:= 5}$\\
                             $\texttt{x}_2\ \texttt{:= x}_1\texttt{-3}$\\
                             \texttt{if} $\texttt{x}_2\texttt{<3}$};
    
            \node[CFG, below right = 12.8mm and 0.2mm of B0] (B1) 
                {$\texttt{y}_2\ \texttt{:= x}_2\texttt{-3}$};
            \node[CFG, below left = 10mm and 0.2mm of B0] (B2) 
                {$\texttt{y}_1\ \texttt{:= x}_2\texttt{*2}$\\
                 $\texttt{w}_1\ \texttt{:= y}_1$};
            \node[CFG, below right = 10mm and -0.3 of B2] (B3) 
                {$\texttt{y}_3\ \texttt{:= }\phi\texttt{(y}_1\texttt{,y}_2\texttt{)}$\\
                 $\texttt{w}_2\ \texttt{:= x}_2\texttt{-y}_3$\\
                 $\texttt{z}_1\ \texttt{:= x}_2\texttt{+y}_3$};

            \draw[-latex, black, very thick] (B0.south) -- (B1.north) {};
            \draw[-latex, black, very thick] (B0.south) -- (B2.north) {};
            \draw[-latex, black, very thick] (B1.south) -- (B3.north) {};
            \draw[-latex, black, very thick] (B2.south) -- (B3.north) {};
        \end{tikzpicture}}
    \end{subfigure}
    \caption{Exemplo de código na forma tradicional e após a conversão para forma SSA.}
    \label{fig:ssa}
\end{figure}

Em seguida, as instruções de definição dos valores são rotuladas como candidatas ou não à rematerialização. Para isso, Briggs \textit{et al.} empregaram um algoritmo semelhante ao \textit{constant propagation} de Wegman e Zadeck \cite{wegman:91}, para propagar as rotulações pelo grafo de controle de fluxo. Os rótulos consistem de:
\begin{itemize}
    \item $\top$ --- significa que nenhuma informação é conhecida. Um valor definido por uma instrução de cópia ou uma função-$\phi$ recebem este rótulo de imediato;
    \item \textit{inst} --- valor definido por uma instrução adequada (\textit{never-killed}. Na implementação é um ponteiro para a própria instrução;
    \item $\bot$ --- valor que deve sofrer \textit{spill}. Valores inapropriados para a rematerialização recebem este rótulo de imediato.
\end{itemize}

Além disso, quando o rótulo de uma variável é propagado para as instruções que a utilizam ocorre uma operação de \textit{``meeting''} ou encontro, denotada pelo símbolo $\sqcap$. Ela é efetuada entre rótulos, e é definida matematicamente através das Fórmulas \ref{eq:meet-1}, \ref{eq:meet-2} e \ref{eq:meet-3}:
\begin{equation}
    x \sqcap \top = x
    \label{eq:meet-1}
\end{equation}
\begin{equation}
    x \sqcap \bot = \bot
    \label{eq:meet-2}
\end{equation}
\begin{equation}
    \mathit{inst}_i \sqcap \mathit{inst}_j = 
    \begin{cases}
        \mathit{inst}_i, & \text{se } \mathit{inst}_i = \mathit{inst}_j \\
        \bot, & \text{se } \mathit{inst}_i \ne \mathit{inst}_j
    \end{cases}
    \label{eq:meet-3}
\end{equation}
onde $x$ é qualquer rótulo, e a comparação $\mathit{inst}_i = \textit{inst}_j$ é realizada operando a operando. Os valores são todos inicializados como $\top$, e durante a propagação valores definidos por uma instrução de cópia terão seus rótulos reduzidos para \textit{inst} ou $\bot$. Valores definidos por funções-$\phi$ serão reduzidos para \textit{inst} se e somente se todos os valores o atingindo tiverem rótulos equivalentes; caso contrário, eles recebem $\bot$.

Concluída a propagação, os nós-$\phi$ devem ser removidos e os valores renomeados para que o programa executável seja produzido. Valores rotulados como \textit{never-killed} são rematerializados no código final e possíveis divisões desnecessárias dos \textit{live ranges}, remanescentes da forma SSA, são removidas através de processos presentes em um alocador estilo Briggs \cite{briggs:92}, como coalescimento e coloração com a mesma cor de variáveis unidas por cópia.

O algoritmo de Briggs \textit{et al.} foi testado em 70 benchmarks, apresentando uma redução considerável de \textit{spill code} em 28 dos casos, com melhorias que ultrapassaram os 20\%. Os autores também observaram uma redução nas instruções de \texttt{store}, \texttt{load} e de cópia, o que indica que as heurísticas de remoção de divisões desnecessárias são adequadas \cite{briggs2:92}.

\section{Coloração de grafos hierárquica}

Em 1991, Callahan e Koblenz \cite{callahan:91} descreveram uma técnica de alocação de registradores que emprega heurística hierárquica de coloração de grafos, onde o programa é particionado em uma série de porções que constituem uma estrutura de árvore e que refletem a estrutura de controle do código. Então, para cada porção é realizada a coloração de grafos de maneira local, resultando numa alocação sensível aos padrões de utilização das variáveis em cada região do programa.

O princípio da abordagem de Callahan e Koblenz consiste em representar o fluxo de repetição e ramificação nos blocos básicos na forma de \textit{``tiles''} que na prática constituem subárvores. Sendo o grafo de controle de fluxo (CFG) representado pela tupla $G = (B, E, \textit{start}, \textit{stop})$, onde $B$ é o conjunto dos blocos básicos, $E$ é o conjunto de arestas entre os blocos e $\mathit{start}, \textit{stop} \in B$ representam respectivamente os pontos de início e fim do fluxo de execução, é definido uma árvore hierárquica $T$.

Cada nó $t \in T$ é um membro da família de subconjuntos de $B$ tal que $\mathit{blocos}(t) = \{b_0, b_1, \dots, b_n\}$ e $\mathit{arestas}(t)=\{e_0, e_1, \dots, e_n\}$, onde $b$ são os blocos básicos pertencentes a $t$, mas que não pertencem a nenhuma subárvore de $t$, e $e$ são as arestas dos blocos em $\mathit{blocos}(t)$. Cada par de elementos em $t_1, t_2 \in T$ é ou disjunto, ou $t_1$ é subconjunto próprio de $t_2$ e não há nenhum outro $t$ tal que $t_1 \subset t \subset t_2$; nesse caso, dizemos que $t_1$ é nó-filho de $t_2$ e $t_2$ é nó-pai de $t_1$. Há também em todo programa uma raiz $t_0$ tal que $\mathit{blocos}(t_0) = \{\mathit{start}, \mathit{stop}\}$. A adição de novos nós na árvore do programa ocorre nas ramificações criadas por estruturas condicionais e em laços de repetição, como exemplificado na Figura \ref{arvore-programa}.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[CFG/.style={rectangle, draw=black!100, fill=white!100, thick, minimum size=20mm, align=center}]
        \node (start) {start};
        \node[CFG, below = of start] (B1) {$B_1$};
        \coordinate[below = 20mm of B1] (C1);
        \node[CFG, left = of C1] (B2) {$B_2$};
        \node[CFG, right = of C1] (B3) {$B_3$};
        \node[CFG, below = of B2] (B4) {$B_4$};
        \node[CFG, below = of B3] (B5) {$B_5$};
        \coordinate[right = of B4] (C2);
        \node[CFG, below = 20mm of C2] (B6) {$B_6$};
        \node[below = of B6] (stop) {stop};

        \draw[-latex, very thick] (start) -- (B1);
        \draw[-latex, very thick] (B1) -- (B2);
        \draw[-latex, very thick] (B1) -- (B3);
        \draw[-latex, very thick] (B2) -- (B4);
        \draw[-latex, very thick] (B3) -- (B5);
        \draw[-latex, very thick] (B4) -- (B6);
        \draw[-latex, very thick] (B5) -- (B6);
        \draw[-latex, very thick] (B6) -- (stop);

        \coordinate[below left = 13.5mm and 8.5mm of B4] (E1);
        \coordinate[above left = 13.5mm and 8.5mm of B4] (E2);

        \coordinate[below right = 13.5mm and 8.5mm of B5] (E3);
        \coordinate[above right = 13.5mm and 8.5mm of B5] (E4);
        
        \draw[-latex, very thick] (B4.south) .. controls (E1) and (E2) .. ([xshift=-5] B4.north);
        \draw[-latex, very thick] (B5.south) .. controls (E3) and (E4) .. ([xshift=5] B5.north);

        \coordinate[below left = of B4] (F1);
        \coordinate[below right = of B4] (F2);
        \coordinate[above left = of B4] (F3);
        \coordinate[above right = of B4] (F4);

        \draw ([xshift = 7mm] current bounding box.north east) -- ([xshift = -7mm] current bounding box.north west) -- ( current bounding box.south west) -- (current bounding box.south east) -- cycle;
        \node at ([xshift = 3mm, yshift = -3mm] current bounding box.north west) {$t_0$};

        \draw ([xshift = -4mm, yshift = -10mm] current bounding box.north east) -- ([xshift = 4mm, yshift = -10mm] current bounding box.north west) -- ([xshift = 4mm, yshift = 10mm] current bounding box.south west) -- ([xshift = -4mm, yshift = 10mm] current bounding box.south east) -- cycle;
        \node at ([xshift = 7mm, yshift = -13mm] current bounding box.north west) {$t_1$};

        \draw ([xshift = 7.5mm, yshift = 7.5mm] B2.north east) -- ([xshift = -7.5mm, yshift = 7.5mm] B2.north west) -- ([xshift = -7.5mm, yshift = -7.5mm] B4.south west) -- ([xshift = 7.5mm, yshift = -7.5mm] B4.south east) -- cycle;
        \node at ([xshift = -4.5mm, yshift = 4.5mm] B2.north west) {$t_2$};

        \draw ([xshift = 7.5mm, yshift = 7.5mm] B3.north east) -- ([xshift = -7.5mm, yshift = 7.5mm] B3.north west) -- ([xshift = -7.5mm, yshift = -7.5mm] B5.south west) -- ([xshift = 7.5mm, yshift = -7.5mm] B5.south east) -- cycle;
        \node at ([xshift = 4.5mm, yshift = 4.5mm] B3.north east) {$t_3$};

        \draw ([xshift = 5mm, yshift = 5mm] B4.north east) -- ([xshift = -5mm, yshift = 5mm] B4.north west) -- ([xshift = -5mm, yshift = -5mm] B4.south west) -- ([xshift = 5mm, yshift = -5mm] B4.south east) -- cycle;
        \node at ([xshift = 2mm, yshift = 2mm] B4.north east) {$t_4$};

        \draw ([xshift = 5mm, yshift = 5mm] B5.north east) -- ([xshift = -5mm, yshift = 5mm] B5.north west) -- ([xshift = -5mm, yshift = -5mm] B5.south west) -- ([xshift = 5mm, yshift = -5mm] B5.south east) -- cycle;
        \node at ([xshift = -2mm, yshift = 2mm] B5.north west) {$t_5$};
    \end{tikzpicture}
    \caption{Exemplo de CFG particionado em porções correspondentes aos nós $t_0,t_1,\dots,t_5$ da árvore hierárquica.}
    \label{arvore-programa}
\end{figure}

Uma vez que a representação intermediária é organizada na forma da árvore hierárquica, a coloração de grafos é efetuada para cada nó de maneira recursiva em pós-ordem, ou \textit{``bottom-up''}. Para cada nó $t$, o grafo é montado contendo somente as variáveis cujo \textit{live range} é definido e usado inteiramente em $\mathit{blocos}(t)$, que são denominadas variáveis locais, e a coloração é feita de maneira convencional seguindo um algoritmo ao estilo de Briggs \cite{briggs:89}. Para todos os fins, as variáveis globais a $t$ --- isto é, que são definidas em níveis superiores da árvore e estão vivas na entrada dos blocos básicos de um nó --- são ignoradas, pois serão tratadas na alocação de algum nó ancestral de $t$. Uma vez concluída a coloração, as variáveis recebem registradores físicos diretamente ou pseudoregistradores, que funcionam como alcunhas para grupos de registradores da arquitetura-alvo. 

Ao retornar para a chamada anterior da recursão, o algoritmo prossegue para colorir o grafo do nó-pai $t_{pai}$ incluindo um conjunto de novas variáveis, cada uma delas sendo o coalescimento de todas as variáveis de $t$ que foram alocadas a um registrador distinto. Elas são denominadas ``variáveis de resumo'', e servem o propósito de indicar quais registradores já foram aproveitados na subárvore com raiz em $t$. Sendo assim, uma aresta é inserida no grafo de interferência de um nó se:
\begin{itemize}
    \item Duas variáveis locais ao nó interferem em algum ponto de seus blocos;
    \item Uma variável global interfere com uma variável de resumo ou outra variável global;
    \item Uma variável está viva em uma subárvore de $t$ mas não consta nas variáveis de resumo vindas da subárvore;
    \item Uma variável de resumo conflita com outras variáveis de resumo da mesma subárvore.
\end{itemize}

Uma vez que a raiz da árvore é colorida, a atribuição final de registradores  físicos ocorre de maneira \textit{``top-down''}, assim como a inserção de instruções de \textit{spill}. O \textit{spill code} é, de maneira geral, inserido nas entradas e saídas dos blocos básicos e consiste de instruções de acesso a memória para variáveis locais que sofreram \textit{spill} em um nó, instruções de cópia para variáveis que receberam registradores diferentes no nó pai e no nó filho, além de instruções \texttt{load} para recarregar valores que receberam um registrador no nó pai mas sofreram \textit{spill} no nó filho.

Para decidir quais \textit{live ranges} devem receber um registrador é empregada uma heurística de decisão de \textit{spill} similar à de Chaitin \cite{chaitin:82}, com a adição de uma nova fórmula para o cálculo de custo desenvolvida por Callahan e Koblenz. Supondo custo unitário para as operações de acesso à memória, são definidas as métricas $\mathit{peso\,local}_t$ (Fórmula \ref{eq:callahan-peso-local}), correspondente ao custo de se manter um valor em registradores físicos levando em conta $\mathit{blocos}(t)$, e $\mathit{transferência}_t$ (Fórmula \ref{eq:callahan-transferencia}), que é o custo de se inserir \textit{spill code} nas entradas e saídas dos blocos de $t$.

\begin{equation}
    \mathit{peso\,local}_t(v) = \sum_{\mathclap{b \in \mathit{blocos}(t)}} \mathit{prob}(b) \mathit{ref}_b(v)
    \label{eq:callahan-peso-local}
\end{equation}
\begin{equation}
    \mathit{transferência}_t(v) = \sum_{\mathclap{e \in \mathit{arestas}(t)}} \mathit{prob}(e) \mathit{viva}_e(v)
    \label{eq:callahan-transferencia}
\end{equation}

As funções $\mathit{prob}(b)$ e $\mathit{prob}(e)$ expressam respectivamente a probabilidade de um bloco e de uma aresta serem executados; $\mathit{ref}_b(v)$ denota o número de referências a $v$ no bloco $b$ e $\mathit{viva}_e(v)$ é uma função booleana que indica se $v$ está viva na aresta $e$. Sendo assim, a heurística de custo que fundamenta a decisão de qual variável deve sofrer \textit{spill} é dada pela função $\mathit{peso}_t$, computada segundo a Fórmula \ref{eq:callahan-peso}:

\begin{equation}
    \mathit{peso}_t(v) = \sum_{\mathclap{\substack{s\\s \text{ é nó-filho de } t}}} (\mathit{reg}_s(v) - \mathit{mem}_s(v)) + \mathit{peso\,local}_t(v)
    \label{eq:callahan-peso}
\end{equation}

O cálculo de $\mathit{peso}_t$ emprega, por sua vez, as métricas definidas nas Fórmulas \ref{eq:callahan-regt} e \ref{eq:callahan-memt}, onde $\mathit{reg?}_t(v)$ retorna $1$ se $v$ já tiver sido alocado a um registrador no nó $t$ e $0$ caso contrário, enquanto $\mathit{mem?}_t(v)$ retorna $1$ se $v$ sofreu \textit{spill} em $t$ e $0$ caso contrário. A função $\mathit{reg}_t(v)$ representa o prejuízo de se fazer \textit{spill} de $v$ no nó-pai de $t$, sendo que a variável foi alocada a um registrador em $t$, enquanto a função $\mathit{mem}_t(v)$ representa o custo de se alocar $v$ a um registrador em um nó-pai sendo que $v$ sofreu \textit{spill} em $t$.

\begin{equation}
    \mathit{reg}_t(v) = \mathit{reg?}_t(v)\text{min}\{\mathit{transferência}_t(v), \mathit{peso}_t(v)\}
    \label{eq:callahan-regt}
\end{equation}

\begin{equation}
    \mathit{mem}_t(v) = \mathit{mem?}_t(v)\mathit{transferência}_t(v)
    \label{eq:callahan-memt}
\end{equation}

O alocador é capaz então de combinar as heurísticas de custo a uma análise da estrutura hierárquica do programa para minimizar a inserção de \textit{spill code}, analisando quando é proveitoso alocar uma variável para registrador ou enviá-la para memória. Por exemplo, pode ser preferível realizar \textit{spill} de uma variável $v$ definida em um nó $t$ que sofreu \textit{spill} em todas as subárvores abaixo de $t$, pois isso tornaria desnecessário todo o \textit{spill code} inserido nos nós descendentes de $t$ e a quantidade de instruções de acesso a memória seria potencialmente reduzida. Nesse caso, $\mathit{peso}_t(v) < 0$ indicaria um desincentivo para se alocar um registrador para $v$, independente de sua coloribilidade.

O principal objetivo atingido por Callahan e Koblenz era o de se obter um método de alocação que tirasse proveito do paralelismo da máquina que executa o compilador. Eles observaram aproveitamento dos recursos de paralelismo ao realizar experimentos com um compilador de Fortran \cite{callahan:91}, confirmando as expectativas prévias da dupla.

\section{\textit{Live Range Splitting}}

Em 1998, Cooper \textit{et al.} \cite{cooper:98} introduziram um novo método heurístico para minimizar a inserção de código \textit{spill}, denominado \textit{live range splitting}. Cooper \textit{et al.} notaram que trabalhos anteriores já haviam proposto técnicas que realizavam a quebra de \textit{live ranges} em pedaços menores e demonstravam melhorias no \textit{spill code} produzido \cite{briggs:92, briggs2:92, chow:84}. No entanto, essas técnicas eram pouco ajustadas e não aproveitavam de maneira eficiente as oportunidades para dividir os \textit{live ranges} e reduzir a quantidade de acessos à memória por serem demasiado agressivas. Sendo assim, eles desenvolveram uma heurística mais precisa para efetuar a quebra dos tempos de vida em pontos estratégicos do programa e obter as melhorias desejadas.

A heurística de Cooper \textit{et al.} usa uma estratégia mais conservadora para efetuar a separação dos tempos de vida ao somente fazê-lo como alternativa à realização de \textit{spill} de uma variável. Dessa maneira, o alocador computaria o custo de se fazer \textit{spill} e compará-lo-ia ao custo de \textit{split} de uma variável candidata, escolhendo a opção menos dispendiosa. Por conseguinte, a separação de \textit{live ranges} ocorre somente em pontos de alta pressão de registradores, onde uma variável é quebrada ao redor de outra de modo a reduzir a pressão, e o \textit{overhead} causado pela criação de novos \textit{live ranges} desnecessários é evitado.

Chaitin \textit{et al.} \cite{chaitin:82} já haviam pontuado que a inserção de \textit{spill code} não elimina completamente as interferências de uma variável, mas apenas reduz a ``área de contato'' ao gerar \textit{live ranges} menores. Cooper \textit{et al.} notaram no entanto que se um \textit{live range} $v_1$ contém completamente um segundo \textit{live range} $v_2$, isto é, $v_1$ é vivo em todos os pontos da definição até o último uso de $v_2$, fazer \textit{spill} de $v_2$ não eliminará a interferência $v_1v_2$. Dessa forma, a única forma de eliminar a interferência para este caso seria efetuar \textit{spill} de $v_1$ ao redor do tempo de vida de $v_2$, efetivamente dividindo $v_1$ em duas partes, como exemplificado pela Figura \ref{fig:splitting-1}.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \begin{tikzpicture}[point/.style={circle, draw=black!100, fill=black!100, minimum size=2mm, align=center}]
            \node[point] (v_1_0) {};
            \node[above = 2mm of v_1_0, scale=1.2] (v_1_label) {$v_1$};
            \node[right = 5mm of v_1_label, scale=1.2] (v_2_label) {$v_2$};
            \node[point, below right = of v_1_0] (v_2_0) {};
            \node[point, below = 20mm of v_2_0] (v_2_1) {};
            \node[point, below left = of v_2_1] (v_1_1) {};
    
            \draw[-, ultra thick] (v_1_0) -- (v_1_1);
            \draw[-, ultra thick] (v_2_0) -- (v_2_1);
        \end{tikzpicture}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \begin{tikzpicture}[point/.style={circle, draw=black!100, fill=black!100, minimum size=2mm, align=center}]
            \node[point] (v_1_0) {};
            \node[above = 2mm of v_1_0, scale=1.2] (v_1_label) {$v_1$};
            \node[right = 5mm of v_1_label, scale=1.2] (v_2_label) {$v_2$};
            \node[point, below right = of v_1_0] (v_2_0) {};
            \node[below = 3mm of v_1_0] (store) {\texttt{store}};
            \node[point, below = 20mm of v_2_0] (v_2_1) {};
            \node[point, below left = of v_2_1] (v_1_1) {};
            \node[above = 3mm of v_1_1] (load) {\texttt{load}};
    
            \draw[-, ultra thick] (v_1_0) -- (store);
            \draw[-, ultra thick] (v_1_1) -- (load);
            \draw[-, ultra thick] (v_2_0) -- (v_2_1);
        \end{tikzpicture}
    \end{subfigure}
    \caption{Exemplo de \textit{splitting}. Nesse caso, $v_1$ é dividido ao redor de $v_2$, eliminando a interferência.}
    \label{fig:splitting-1}
\end{figure}

De modo a contemplar as relações de contenção entre os \textit{live ranges}, o \textit{live range splitting} requer a construção de um grafo direcionado $C$, denominado grafo de contenção. Os nós de $C$ representam as variáveis, enquanto uma aresta $e=(v_2,v_1)$ indica que $v_1$ estava vivo em uma definição ou uso de $v_2$. A Figura \ref{fig:splitting-2} exemplifica as possíveis relações entre os tempos de vida, baseado nos pontos onde são definidos e usados em relação uns aos outros.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{0.30\textwidth}
        \centering
        \adjustbox{valign=t}{\begin{tikzpicture}
            \node (v_1_0) {def $v_1$};
            \node[below right = of v_1_0] (v_2_0) {def $v_2$};
            \node[below left = of v_2_0] (use) {};
            \node[below right = of use] (v_2_1) {use $v_2$};
            \node[below left = of v_2_1] (v_1_1) {use $v_1$};

            \draw[-, ultra thick] (v_1_0) -- (v_1_1);
            \draw[-, ultra thick] (v_2_0) -- (v_2_1);
        \end{tikzpicture}}
    \end{subfigure}
    \unskip\ \vrule\ 
    \begin{subfigure}[t]{0.30\textwidth}
        \centering
        \adjustbox{valign=t}{\begin{tikzpicture}
            \node (v_1_0) {def $v_1$};
            \node[below right = of v_1_0] (v_2_0) {def $v_2$};
            \node[below left = of v_2_0] (use) {use $v_1$};
            \node[below right = of use] (v_2_1) {use $v_2$};
            \node[below left = of v_2_1] (v_1_1) {};

            \draw[-, ultra thick] (v_1_0) -- (use);
            \draw[-, ultra thick] (v_2_0) -- (v_2_1);
        \end{tikzpicture}}
    \end{subfigure}
    \unskip\ \vrule\ 
    \begin{subfigure}[t]{0.30\textwidth}
        \centering
        \adjustbox{valign=t}{\begin{tikzpicture}
            \node (v_1_0) {def $v_1$};
            \node[below right = of v_1_0] (v_2_0) {def $v_2$};
            \node[below left = of v_2_0] (use) {use $v_1$};
            \node[below right = of use] (v_2_1) {use $v_2$};
            \node[below left = of v_2_1] (v_1_1) {use $v_1$};

            \draw[-, ultra thick] (v_1_0) -- (use);
            \draw[-, ultra thick] (v_1_1) -- (use);
            \draw[-, ultra thick] (v_2_0) -- (v_2_1);
        \end{tikzpicture}}
    \end{subfigure} \\
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}[C/.style={draw,circle, scale=1.2}]
            \node[C] (v_1) {$v_1$};
            \node[C, right = of v_1] (v_2) {$v_2$};

            \draw[-latex, very thick] (v_2) -- (v_1);
        \end{tikzpicture}
        \caption{}
        \label{fig:splitting-2:a}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}[C/.style={draw,circle, scale=1.2}]
            \node[C] (v_1) {$v_1$};
            \node[C, right = of v_1] (v_2) {$v_2$};
            \draw[-latex, very thick] (v_2.north west) -- (v_1.north east);
            \draw[-latex, very thick] (v_1.south east) -- (v_2.south west);
        \end{tikzpicture}
        \caption{}
        \label{fig:splitting-2:b}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}[C/.style={draw,circle, scale=1.2}]
            \node[C] (v_1) {$v_1$};
            \node[C, right = of v_1] (v_2) {$v_2$};
            \draw[-latex, very thick] (v_2.north west) -- (v_1.north east);
            \draw[-latex, very thick] (v_1.south east) -- (v_2.south west);
        \end{tikzpicture}
        \caption{}
        \label{fig:splitting-2:c}
    \end{subfigure}
    \caption{Relações de contenção entre dois \textit{live ranges} e seus respectivos grafos. Adaptado de Cooper \textit{et al.} \cite{cooper:98}}
    \label{fig:splitting-2}
\end{figure}

A coluna \hyperref[fig:splitting-2:a]{(a)} mostra a mesma situação da Figura \ref{fig:splitting-1}, onde $v_2$ não está vivo em nenhum ponto de definição ou uso de $v_1$ e portanto está inteiramente contido em $v_1$, logo $(v_2,v_1) \in C$. Em \hyperref[fig:splitting-2:b]{(b)} ambas os \textit{live ranges} se sobrepõe, então ambos os caminhos $(v_1,v_2)$ e $(v_2,v_1)$ estão em $C$. O caso \hyperref[fig:splitting-2:c]{(c)} tem o mesmo resultado de \hyperref[fig:splitting-2:b]{(b)} devido à ocorrência de um uso de $v1$ em meio ao tempo de vida de $v_2$. A Tabela \ref{tab:splitting-1} resume as possibilidades de \textit{splitting} ou \textit{spilling} de acordo com a ocorrência de arestas no grafo de contenção $C$.

\begin{table}[hb]
    \centering
    \begin{tabular*}{.65\textwidth}{@{\extracolsep{\fill}} c c}
        Arestas em $C$ & Efeito na geração de \textit{spill code} \\
        \hline
        $(v_i,v_j)$ & A divisão de $v_j$ ao redor de $v_i$ elimina\\
         & a interferência. O \textit{spill} de $v_i$, não.\\
        $(v_j,v_i)$ & A divisão de $v_i$ ao redor de $v_j$ elimina\\
         & a interferência. O \textit{spill} de $v_j$, não.\\
        $(v_i,v_j)$ e $(v_j,v_i)$ & Não se pode dividir nenhum dos dois.\\
         & Nenhum \textit{spill} remove a interferência.
    \end{tabular*}
    \caption{Casos de \textit{splitting} de acordo com a ocorrência de arestas no grafo de conteção $C$. Adaptado de Cooper \textit{et al.} \cite{cooper:98}.}
    \label{tab:splitting-1}
\end{table}

Uma vez conhecidas as variáveis aptas a serem divididas com sucesso, o custo de fazê-lo deve ser computado pelo alocador para decidir entre \textit{spill} ou \textit{split}. O custo da divisão de cada \textit{live range} $v$ é obtido contando uma instrução \texttt{store} antes da definição e uma instrução \texttt{load} após o último uso, o que pode ser facilmente incorporado à fase de \textit{spill costs} de um alocador ao estilo Briggs. Caso $v$ seja escolhido para \textit{spill} durante a fase de seleção, uma cor deve ser encontrada para $v$ com base no custo de dividi-la em $v$ ou o contrário. Se uma cor for encontrada, $v$ a recebe e os tempos de vida correspondentes são marcados para divisão.

Foram realizados experimentos com 32 \textit{benchmarks} e obteve-se resultados positivos na maioria deles. Em alguns casos, a diminuição na contagem de instruções de acesso à memória chegou a 78\%. No entanto, dois casos de teste apresentaram uma maior inserção de \textit{spill code}, e o \textit{live range splitting} obteve piores resultados quando comparado ao \textit{spilling} por região de interferência para mais da metade dos casos. Apesar disso, Cooper \textit{et al.} ressaltaram a viabilidade de combinar ambas as técnicas em um alocador capaz de decidir qual delas utilizar.

\section{\textit{Outras Técnicas}}

\textbf{Coloração prioritária} --- Chow \textit{et al.} publicaram em 1984 um trabalho descrevendo um algoritmo de coloração de grafos similar ao de Chaitin \cite{chaitin:82}, mas com a aplicação de uma heurística de prioridade para a etapa de seleção. O alocador computa a diferença de custo entre se armazenar uma variável na memória ou e em um registrador físico e, no processo de coloração, é dada prioridade aos vértices cujo custo do \textit{live range} associado é o mais promissor. Experimentos foram realizados em 13 \textit{benchmarks} consistindo de programas Pascal e Fortran, e foi observada uma melhora média de 39\% no tempo de execução dos binários gerados.

\chapter{Aprendizado de Máquina}

O aprendizado de máquina ou \textit{``machine learning''}, em inglês, é uma área da inteligência artificial que se encarrega do desenvolvimento de agentes inteligentes que se tornam precisos ao aprenderem a partir de dados e melhorarem a si mesmos, em vez de serem explicitamente programados para tal. Esse processo de aprendizado, denominado ``treinamento'', comumente envolve a utilização de um conjunto de dados contendo os resultados esperados de um determinado problema, que são contrastados com os resultados produzidos pelo modelo de inteligência artificial para que o próprio modelo aprimore a si mesmo \cite{alzubi:18}.

O aprendizado de máquina é particularmente útil para problemas cujos quais não há um algoritmo predefinido para resolvê-los, mas há uma grande disponibilidade de dados. Embora não seja possível encontrar uma solução exata, através da análise dos dados e apoiando-se em fundamentos da estatística e probabilidade é possível obter uma aproximação suficientemente precisa \cite{alpaydin:20}. A Figura \ref{fig:ml-esquema} ilustra o processo de desenvolvimento de um modelo genérico de \textit{machine learning}, desde o preparo dos dados até a etapa de avaliação da performance do agente inteligente.

\begin{figure}[htb]
    \centering
    \begin{tikzpicture}[
        node distance= 0.5cm and 0.5cm,
        node/.style={draw, align=center, minimum width=2.7cm, minimum height=1.7cm},
        arrow/.style={very thick, ->, >=stealth}, scale=0.5
    ]
        \node[node] (n0) {Coleta dos\\dados};
        \node[node, right = of n0] (n1) {Seleção dos\\atributos};
        \node[node, right = of n1] (n2) {Escolha do\\algoritmo};
        \node[node, below = of n2] (n3) {Escolha do\\modelo e\\parâmetros};
        \node[node, left = of n3] (n4) {Treinamento};
        \node[node, left = of n4] (n5) {Avaliação de\\performance};

        \draw[arrow] (n0) -- (n1);
        \draw[arrow] (n1) -- (n2);
        \draw[arrow] (n2) -- (n3);
        \draw[arrow] (n3) -- (n4);
        \draw[arrow] (n4) -- (n5);
    \end{tikzpicture}
    \caption{Esquema ilustrando o desenvolvimento de um modelo genérico de \textit{machine learning}. Adaptado de Alzubi \textit{et al.} \cite{alzubi:18}.}
    \label{fig:ml-esquema}
\end{figure}

Sendo assim, as soluções do aprendizado de máquina consistem da identificação de padrões regulares na natureza do problema e na utilização desses padrões para realizar predições. Dentre as tarefas mais comuns dos modelos de \textit{machine learning} encontram-se \cite{alzubi:18}:

\begin{itemize}
    \item \textbf{Classificação} --- classificar os dados de entrada em um conjunto fixo de classes de saída conhecidos antecipadamente como sim ou não, verdadeiro ou falso, dentre outras;
    \item \textbf{Detecção de anomalias} --- buscar padrões nos dados de entrada de modo a identificar desvios ou anomalias. Exemplos reais incluem análise de tráfego de rede e identificação de transações fraudulentas;
    \item \textbf{Regressão} --- encontrar uma função matemática que descreva o resultado para uma dada entrada, com base nos dados disponíveis para treinamento. Exemplos são a estimativa de tendências de crescimento de preços ou crescimento populacional;
    \item \textbf{Agrupamento} --- encontrar estruturas nos dados e separá-los em grupos. Um exemplo real é a análise de texto para agrupá-los por classe de documentos semelhantes.
\end{itemize}

Com o avanço da capacidade de armazenamento e das tecnologias de redes nas últimas décadas, tornou-se possível armazenar e processar grandes quantidades de dados, bem como acessá-los remotamente por meio da internet. Isso viabilizou o amplo emprego das técnicas de aprendizado de máquina em uma série de aplicações \cite{alpaydin:20, sharma:21}, incluindo a criação de compiladores e a geração de \textit{spill code}, o que será abordado no Capítulo \ref{sec:trabalhos-correlatos} deste trabalho. O restante do atual Capítulo irá sumarizar a fundamentação teórica por trás dos principais paradigmas de aprendizado e técnicas de implementação de modelos de \textit{machine learning}.

\section{Aprendizado Supervisionado}

No paradigma de aprendizado supervisionado, cada entrada do conjunto de dados de treinamento é rotulada de acordo com as variáveis relevantes ao processo de aprendizagem. Em termos formais, cada elemento do conjunto de treinamento é definido como composto pelo vetor das variáveis de entrada $\Vec{X}$ e um rótulo $r$, tal que o conjunto de treinamento seja caracterizado por um mapeamento $m : \Vec{X} \to \{r_1, r_2, \dots, r_n\}$. O processo de treinamento então visa ajustar o modelo para produzir um mapeamento $m' : \Vec{X} \to \{r_1, r_2, \dots, r_n\}$, onde $m'$ é suficientemente próximo da relação $m$ original presente no conjunto de treinamento \cite{mohammed:16, alpaydin:20}.

Neste contexto, os rótulos para o vetor de saída são fornecidos por um supervisor, que pode ser tanto um humano quanto uma máquina. Embora a rotulagem por humanos seja mais cara e demorada, os erros mais frequentes na rotulagem feita por máquinas sugerem a superioridade do julgamento humano. Dados rotulados manualmente são considerados recursos valiosos e confiáveis para o aprendizado supervisionado, embora em alguns casos, máquinas também possam ser usadas para rotulagem confiável \cite{mohammed:16}.

Na Figura \ref{fig:plot-supervisionado}, um conjunto de treinamento contendo 4 elementos, cada qual formado por um vetor de entrada $\Vec{X} = [x_1,x_2]^T$ e rotulado como $\{r_1, r_2\}$, forma um espaço bidimensional. Após um treinamento supervisionado um modelo inteligente encontra a classificação $C$, que compreende os elementos do conjunto que possuem o rótulo $r_1$. A Tabela \ref{tab:rotulos} demonstra possíveis rotulações para conjuntos de dados não-rotulados, a serem atribuídos por um agente supervisor.

\begin{figure}[hbt]
    \centering
    \begin{tikzpicture}[scale=1.2]
        % Eixos como réguas
        \draw[->] (0, 0) -- (5.5, 0) node[right] {$x_1$};
        \draw[->] (0, 0) -- (0, 5.5) node[above] {$x_2$};
        
        % Pontos no primeiro quadrante
        \foreach \x/\y/\label in {1/1/r_2, 3/2/r_1, 2/4/r_1, 4/3/r_1}
        {
        \fill (\x, \y) circle (2pt) node[above right] {$\label$};
        }
        
        \draw[dashed] (1.5, 1.5) rectangle (4.5, 4.5) node[above right] {$C$};
    \end{tikzpicture}
    \caption{Análise gráfica considerando um conjunto de treinamento com 4 elementos, formados pelos parâmetros de entrada $\Vec{X} = [x_1,x_2]^T$ e rótulos $\{r_1, r_2\}$.}
    \label{fig:plot-supervisionado}
\end{figure}

\begin{table}[htb]
    \centering
    \begin{tabular}{c|c|c}
        Exemplo de dado & Critério de rotulação & Possíveis rótulos \\ \hline
        \textit{Tweet} & Sentimento do \textit{tweet} & $\{\text{positivo},\text{negativo}\}$ \\
        Imagem & Contém uma casa ou carro? & $\{\text{sim},\text{não}\}$ \\
        Áudio & A palavra ``futebol'' é dita & $\{\text{sim},\text{não}\}$ \\
        Vídeo & Armas são mostradas no vídeo? & $\{\text{violento},\text{não-violento}\}$ \\
        Raio X & Presença de tumor no raio X & $\{\text{presente},\text{ausente}\}$
    \end{tabular}
    \caption{Exemplos de dados não-rotulados e possíveis critérios de rotulação a um possível supervisor. Extraído de Mohammed \textit{et al.} \cite{mohammed:16}}
    \label{tab:rotulos}
\end{table}

\section{Aprendizado Não-Supervisionado}

No paradigma não-supervisionado, não há um supervisor para rotular os elementos do conjunto de entrada. Essa abordagem foca em reconhecer padrões não identificados previamente nos dados para derivar os critérios de classificação ou regressão a partir deles. Essa técnica é adequada para processar grandes volumes de dados onde a rotulação é demasiado trabalhosa ou impossível, realizando análises estatísticas para descobrir estruturas ocultas em dados não-rotulados \cite{mohammed:16}. 

Dentre os principais métodos de aprendizado não-supervisionado destacam-se o agrupamento (\textit{clustering}) e a redução de dimensionalidade. O agrupamento envolve a tarefa de identificar grupos ou \textit{clusters} de dados semelhantes com base em suas características, permitindo a segmentação de dados em categorias não conhecidas previamente. A redução de dimensionalidade busca representar dados complexos em um espaço de menor dimensão, preservando as características importantes, o que é útil para simplificar a análise de dados de alta dimensionalidade e visualização \cite{usama:19}. 

Algoritmos populares incluem o $k$-\textit{means} para agrupamento, que divide os dados em \textit{clusters}, ou agrupamentos, com base na proximidade dos pontos de dados uns com os outros espaço $n$-dimensional \cite{alpaydin:20, mohammed:16}, e a análise de componentes principais (PCA) para redução de dimensionalidade, que é uma técnica que reduz a dimensionalidade dos dados, mantendo as informações mais importantes e descartando as menos importantes \cite{gorban:10}. 

A Figura \ref{fig:k-means} mostra dados plotados em 2 dimensões divididos em 2 \textit{clusters}, cujos centroides \footnote{O centroide corresponde ao ponto médio de todos os elementos de um determinado agrupamento no espaço $k$-dimensional.} são indicados por um ``$\times$''. A Figura \ref{fig:pca} mostra uma visualização de um conjunto de dados de \textit{microarray} sobre câncer de mama usando mapas elásticos. O \textit{plot} (a) mostra nós projetados em um espaço tridimensional; o conjunto de dados é curvo e não pode ser adequadamente mapeado em um plano principal bidimensional. O \textit{plot} (b) mostra a distribuição nas coordenadas internas da superfície principal não linear bidimensional e (c) o mesmo que (b), mas para o espaço linear bidimensional após realização do PCA.

\begin{figure}[hbt]
    \centering
    \includegraphics[width=.6\textwidth]{pca}
    \caption{\textit{Plot} de um conjunto de dados de \textit{microarray} de câncer de mama usando mapas elásticos, empregando técnicas de análise de componentes principais. Extraído de Gorban e Zinovyev \cite{gorban:10}.}
    \label{fig:pca}
\end{figure}

\begin{figure}[hbt]
    \centering
    \includegraphics[width=.5\textwidth]{k-means}
    \caption{Exemplo de aplicação do $k$-\textit{means}. Os centroides dos \textit{clusters} são indicados com um ``$\times$'' no gráfico. Extraído de Alpaydin \cite{alpaydin:20}.}
    \label{fig:k-means}
\end{figure}

\section{Aprendizado Semi-supervisionado}

No aprendizado semi-supervisionado os dados fornecidos consistem em uma mistura de dados rotulados e não rotulados. Essa combinação de ambos os tipos é usada para criar um modelo apropriado para a classificação de dados sendo que, frequentemente, os dados rotulados são escassos, enquanto os não rotulados são abundantes. O objetivo da classificação semi-supervisionada é aprender um modelo que preveja as classes de dados de teste futuros melhor do que um modelo gerado apenas com os dados rotulados. Isso permite aproveitar ao máximo os dados não rotulados disponíveis para melhorar o desempenho da classificação \cite{mohammed:16}.

Alguns dos principais métodos de treinamento empregados no aprendizado semi-supervisionado incluem, dentre outros \cite{prakash:14, vanengelen:20}: 

\begin{enumerate}
    \item \textbf{Modelos generativos} --- visam aprender a distribuição de probabilidade dos dados não rotulados com base nos dados rotulados conhecidos. Eles permitem não apenas fazer previsões ou classificações, mas também gerar novos dados que se assemelham aos dados de treinamento. Esses modelos são úteis para a geração de dados sintéticos e para melhorar o desempenho da classificação;
    \item \textit{\textbf{Self-training}} --- um agente classificador é treinado usando os dados rotulados, e em seguida é usado para rotular o restante dos dados não classificados do conjunto de treinamento;
    \item \textit{\textbf{Co-training}} --- se baseia na ideia de usar múltiplas visualizações ou conjuntos de características dos dados para treinar modelos independentes. Essa abordagem é particularmente útil quando os dados disponíveis podem ser divididos em diferentes visualizações que fornecem informações complementares.
\end{enumerate}

\section{Aprendizado por Reforço}

No aprendizado por reforço, o agente inteligente toma decisões em um ambiente e recebe recompensas (ou penalidades) por suas ações ao tentar resolver um problema e, após uma série de tentativas e erros, o agente deve apresentar a melhor política de tomada de decisões, que é a sequência de ações que maximiza a recompensa total \cite{alpaydin:20}. A política é dada pelo mapeamento $\pi : A \times S \to [0,1]$, onde $A$ é o conjunto das ações e $S$ é o conjunto dos estados de \textit{input}. A política $\pi(a,s)$ retorna a probabilidade da ação $a \in A$ ser tomada dado o estado $s \in S$ do ambiente \cite{kaelbiling:96}.

O treinamento se dá de maneira iterativa, quando o agente observa o estado de entrada no ambiente e, em seguida, utiliza uma função de tomada de decisão para escolher e realizar uma ação específica. Após a execução da ação, o agente recebe uma recompensa ou reforço do ambiente, que pode ser positiva (indicando uma ação benéfica) ou negativa (indicando uma ação prejudicial). A geração de políticas de tomada de decisão pode ser feita através de força-bruta ou empregando heurísticas fundamentadas em processos estocásticos para a escolha da próxima ação, se baseando nas ações prévias do sistema e o atual estado \cite{mohammed:16, kaelbiling:96}, sendo que esse processo é ilustrado pela Figura \ref{fig:rl}.

\begin{figure}[hbt]
    \centering
    % \includegraphics[scale=1.2]{rl}
    \begin{tikzpicture}
        \node (agente) {
            \adjustbox{scale=0.7}{\begin{tikzpicture}[text centered, draw=black, node distance=1.5cm, >=Stealth, thick]
            
            % Camada de entrada
            \foreach \i in {1,...,4}
                \node[circle, draw, minimum size=0.75cm] (I-\i) at (0,-\i) {};
            
            % Camada oculta
            \foreach \h [count=\hi] in {1,...,4} % Ajuste o número de nós na camada oculta
                \node[circle, draw, minimum size=0.75cm, right = 1cm of I-\h] (H-\h) {};
    
            % Conexões entre camadas
            \foreach \i in {1,...,4}
                \foreach \h in {1,...,4}
                    \draw[-] (I-\i) -- (H-\h);
            \end{tikzpicture}}
            };
        \node[above = 1mm of agente] {Agente};
        \coordinate[right = 35mm of agente] (a);
        \node[draw, right = 35mm of a, minimum width = 1cm, minimum height = 3cm] (ambiente) {Ambiente};
        \node[below = 30mm of a, draw, circle] (inter) {Intérprete};

        \draw[->, -latex, very thick] (agente) -- node[above=1mm] {Ação} (ambiente);
        \path[->, -latex, very thick] (ambiente.south) edge[bend left] (inter);
        \path[->, -latex, very thick] (inter) edge[bend left] node[right=3mm] {Estado} (agente.290);
        \path[->, -latex, very thick] (inter) edge[bend left] node[left=3mm] {\textit{Feedback}} (agente.250);
    \end{tikzpicture}
    \caption{Esquema do processo de treinamento via aprendizado por reforço.}
    \label{fig:rl}
\end{figure}

O aprendizado por reforço difere dos outros paradigmas de aprendizado de várias maneiras; a diferença mais importante é a não utilização de pares de entrada/saída esperada, como no aprendizado supervisionado. Em vez disso, depois de escolher uma ação, o agente é informado sobre a recompensa imediata e o estado subsequente, mas não é informado sobre qual ação teria sido do seu melhor interesse a longo prazo. É necessário para o agente adquirir experiência útil sobre os possíveis estados do sistema, ações, transições e recompensas ativamente para agir de forma otimizada. Outra diferença em relação ao aprendizado supervisionado é que o desempenho em tempo real é importante: a avaliação do sistema muitas vezes ocorre simultaneamente ao aprendizado \cite{kaelbiling:96}.

\section{Redes Neurais Artificiais e Aprendizado Profundo}

As redes neurais artificiais (ANNs) constituem uma classe de modelos de inteligência artificial que têm como inspiração para seu funcionamento o sistema nervoso dos animais. As redes neurais são compostas de uma série de unidades chamadas neurônios, que funcionam como pequenos computadores de função individuais; cada neurônio artificial recebe uma ou mais entradas, computa uma função matemática tendo como parâmetros as entradas recebidas e produz uma saída, que é propagada para a camada seguinte. Uma rede neural possui ao menos uma camada de entrada e uma camada de saída, que apresenta o resultado \cite{krogh:08, mathew:21}.

As redes neurais que resolvem problemas de classificação são chamadas de ``\textit{percéptrons}'', ao dividir o espaço dos valores de entrada com uma série de hiperplanos\footnote{Generalização do conceito de plano para dimensões maiores. Dado um espaço $k$-dimensional, um hiperplano é um subespaço $k-1$-dimensional. O correspondente a um hiperplano em um espaço bidimensional é uma reta; em um espaço tridimensional, é um plano propriamente dito.}, onde os valores de cada lado dos hiperplanos pertencem a classes distintas. Problemas onde é necessário o uso de somente um hiperplano são ditos linearmente separáveis, e podem ser resolvidos por redes neurais simples. Entretanto, grande parte dos problemas reais não são linearmente separáveis. Nesses casos, é necessário a utilização de mais hiperplanos através da introdução de camadas ocultas na rede neural que realizam, cada uma, classificações parciais que são repassadas à camada seguinte, até que se chegue na camada final \cite{krogh:08, alpaydin:20}.

\begin{figure}[hbt]
    \centering
    \begin{subfigure}{.49\textwidth}
        \centering
        \adjustbox{scale=1.4, valign=c}{\begin{tikzpicture}[node distance=2cm,->,-latex]
            \node [draw, circle, text width=1em, text centered, minimum height=2em] (input1) {$x_1$};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, below of=input1] (input2) {$x_2$};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, below of=input2] (input3) {$x_3$};
            % Camada oculta
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=input1] (hidden1) {};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=input2] (hidden2) {};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=input3] (hidden3) {};
            
            % Camada de saída
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=hidden2] (output) {$y$};
            
            % Conexões
            \path (input1) edge (hidden1);
            \path (input1) edge (hidden2);
            \path (input1) edge (hidden3);
            \path (input2) edge (hidden1);
            \path (input2) edge (hidden2);
            \path (input2) edge (hidden3);
            \path (input3) edge (hidden1);
            \path (input3) edge (hidden2);
            \path (input3) edge (hidden3);
            \path (hidden1) edge (output);
            \path (hidden2) edge (output);
            \path (hidden3) edge (output);
        \end{tikzpicture}}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \adjustbox{scale=1.4, valign=c}{\begin{tikzpicture}[node distance=2cm,->,-latex]
            \node [draw, circle, text width=1em, text centered, minimum height=2em] (input1) {$x_1$};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, below of=input1] (input2) {$x_2$};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, below of=input2] (input3) {$x_3$};
            % Camada oculta
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=input1] (hidden1) {};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=input2] (hidden2) {};
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=input3] (hidden3) {};
            
            % Camada de saída
            \node [draw, circle, text width=1em, text centered, minimum height=2em, right of=hidden2] (output) {$y$};

            \coordinate[above right = 0.5cm and 0.8cm of hidden1.north east] (h1_b1);
            \coordinate[below right = 0.5cm and 0.8cm of hidden1.335] (h1_b2);
            \coordinate[above right = 0.5cm and 0.8cm of hidden3.25] (h2_b1);
            \coordinate[below right = 0.5cm and 0.8cm of hidden3.south east] (h2_b2);
            
            % Conexões
            \path (input1) edge (hidden1);
            \path (input1) edge (hidden2);
            \path (input1) edge (hidden3);
            \path (input2) edge (hidden1);
            \path (input2) edge (hidden2);
            \path (input2) edge (hidden3);
            \path (input3) edge (hidden1);
            \path (input3) edge (hidden2);
            \path (input3) edge (hidden3);
            \path (hidden1) edge (output);
            \path (hidden2) edge (output);
            \path (hidden3) edge (output);
            \path (hidden2) edge (hidden3);
            \path (hidden2) edge (hidden1);
            \draw[->, -latex] (hidden1.335) .. controls (h1_b2) and (h1_b1) .. (hidden1.north east);
            \draw[->, -latex] (hidden3.25) .. controls (h2_b1) and (h2_b2) .. (hidden3.south east);
        \end{tikzpicture}}
    \end{subfigure}    
    \caption{Uma rede neural \textit{feed-forward} e uma rede neural recorrente, na esquerda e direita respectivamente.}
    \label{fig:ann}
\end{figure}

Quando uma rede neural possui uma ou mais camadas intermediárias entre a entrada e a saída, ela é denominada ``rede neural profunda'', e seu processo de treinamento é chamado de aprendizado profundo, ou \textit{``deep learning''}. Como mostrado na Figura \ref{fig:ann}, as redes neurais profundas podem ter uma organização \textit{``feed-forward''}, forma mais amplamente utilizada e que apresenta um fluxo unidirecional de uma camada para outra, ou recorrente, que pode conter ciclos e possuir um fluxo bidirecional entre as camadas \cite{mathew:21}.

A estrutura básica de um neurônio artificial é mostrada na Figura \ref{fig:neuronio}. Ele recebe uma ou mais entradas $x_1$, $x_2$, $\dots$, $x_n$, cada qual associada a um peso dentre $w_1$, $w_2$, $\dots$, $w_n$, e realiza uma soma ponderada para produzir uma saída, também chamada de ativação. Em certos casos a soma é adicionada a um termo $b$ conhecido como viés ou limiar, antes de passar por uma função $f$ não linear chamada função de ativação ou função de transferência. 

\begin{figure}[hbt]
    \centering
    \adjustbox{scale=1.2}{\begin{tikzpicture}[text centered]
        \node (x_1) {$x_1$};
        \node[below = of x_1] (x_2) {$x_2$};
        \node[below = of x_2] (x_3) {$x_n$};

        \coordinate (intermediate) at ($(x_2)!0.5!(x_3)$);
        \node[text centered] (c) at (intermediate) {\Large $\vdots$};
        
        \node[right = 2cm of x_2, circle, draw=black, minimum width=1.5cm] (neuronio) {$\sum w_ix_i$};
        \node[above = 0.4cm of neuronio] (b) {$+b$};
        \coordinate[above = 0.4cm of b] (l);
    
        \coordinate (c1) at ($(x_1)!0.38!(neuronio)$);
        \coordinate (c2) at ($(x_2)!0.38!(neuronio)$);
        \coordinate (c3) at ($(x_3)!0.38!(neuronio)$);
        
        \node (w1) at (c1) {$w_1$};
        \node (w2) at (c2) {$w_2$};
        \node (w3) at (c3) {$w_n$};
        
        \node[right = of neuronio, draw, minimum width = 0.5cm, minimum height = 2cm] (vies) {\Large $f$};
        
        \draw[-] (x_1) -- (w1);
        \draw[->,-latex] (w1) -- (neuronio);
        \draw[-] (x_2) -- (w2);
        \draw[->,-latex] (w2) -- (neuronio);
        \draw[-] (x_3) -- (w3);
        \draw[->,-latex] (w3) -- (neuronio);

        \draw[-] (l) -- (b);
        \draw[->,-latex] (b) -- (neuronio);

        \draw[-] (neuronio) -- (vies);
        \coordinate[right = 1cm of vies] (a);
        \draw[->,-latex] (vies) -- (a);
    \end{tikzpicture}}
    \caption{Esquema do funcionamento básico de um neurônio artificial.}
    \label{fig:neuronio}
\end{figure}

As funções de transferência geralmente possuem uma forma sigmoide, mas também podem adotar a forma de outras funções não-lineares, funções lineares em partes ou funções degrau. Algumas importantes funções usadas como limiar incluem \cite{sharma:20}:

\begin{itemize}
    \item \textbf{\textit{Função degrau}} --- saída binária, se a entrada for maior que um limite especificado $\theta$:
    \[f(x) = \begin{cases}
        1, & x \geq \theta\\
        0, & \text{caso contrário}.
    \end{cases}\]
    \item \textbf{\textit{Função logística}} --- função sigmoide (curva em forma de ``S''), utilizada para gerar um valor no intervalo $[0,1]$:
    \[
        f(x) = \frac{1}{1+e^{-x}}
    \]
    \item \textbf{\textit{Tangente hiperbólica}} --- função sigmoide com domínio limitado no intervalo $[-1,1]$, sendo simétrica em torno de $0$:
    \[
        f(x) = \tanh{x} = \frac{e^x - e^{-x}}{e^x + e^{-x}}
    \]
    \item \textbf{\textit{Rectified Linear Unit} (ReLU)} --- retorna a entrada se for positiva e zero caso contrário. É uma função de ativação popular em redes neurais profundas devido à eficiência no processo de treinamento:
    \[
        f(x) = \text{max }\{0, x\}
    \]
\end{itemize}

O treinamento dos modelos de rede neural pode ser feito através de um série de algoritmos, dentre os quais se destaca o método do \textit{back-propagation}, ou retropropagação, que faz uso de uma técnica de otimização numérica chamada descida gradiente para o treinamento de redes profundas \textit{feed-forward}. A rede é inicializada com todos os seus pesos recebendo valores aleatórios e a primeira iteração é realizada, onde uma entrada é analisada e é produzida uma saída aleatória. Em seguida, é calculado um erro, igual ao quadrado da diferença entre o último resultado e o resultado esperado, e os parâmetros da rede (pesos e limiares) são ajustados de modo a reduzir o erro calculado. Esse processo é repetido inúmeras vezes, até que se obtenha o conjunto de pesos que minimizam o erro, e produzam um resultado muito próximo do esperado \cite{krogh:08}.

Redes neurais profundas, incluindo as \textit{feed-forward} e as recorrentes, desempenham um papel fundamental em uma ampla variedade de aplicações. Na visão computacional, elas são usadas para tarefas como detecção de objetos, reconhecimento facial e classificação de imagens. No processamento de linguagem natural, auxiliam na análise de sentimento, tradução automática, geração de texto e reconhecimento de fala. Já as redes neurais recorrentes destacam-se no processamento de sequências, como tradução automática e geração de texto coerente, bem como na modelagem de linguagem. A versatilidade do \textit{deep learning} e a capacidade de aprender padrões complexos apresentada pelas redes neurais profundas as tornam essenciais em muitos campos, e representam um grande horizonte a ser investigado nas pesquisas \cite{sharma:21}.

\chapter{Trabalhos Correlatos} \label{sec:trabalhos-correlatos}

Com a recente expansão da pesquisa em torno do aprendizado de máquina, uma variedade de trabalhos foram realizados buscando integrar as soluções de \textit{machine learning} à área de compiladores em geral e, consequentemente, aos problemas da alocação de registradores e geração de código \textit{spill}. Todavia, alguns obstáculos se fizeram presentes, como a indisponibilidade de \textit{datasets} para treinamento e a necessidade por corretude nos algoritmos de geração de código, contrastando com a natureza aproximada das soluções produzidas por modelos de \textit{machine learning} \cite{venkatakeerthy:23}.

Ainda assim, uma variedade de trabalhos apresentam resultados promissores ao utilizar técnicas de aprendizado de máquina para a obtenção de melhores heurísticas e promover uma minimização de \textit{spill code} mais eficiente. Este Capítulo tem por objetivo expor alguns desses trabalhos e apresentar um panorama do estado da arte das pesquisas recentes combinando aprendizado e máquina e alocação de registradores.

\section{\textit{Meta Optimization}}

Em 2003, Stephenson \textit{et al.} \cite{amarasinghe:03} publicaram um trabalho que discute o uso de técnicas de aprendizado de máquina para ajustar automaticamente as heurísticas de várias etapas de otimização, incluindo a alocação de registradores. Dessa forma, os autores introduzem o conceito de \textit{``Meta Optimization''} ou metaotimização, em uma tradução livre, uma metodologia que emprega \textit{machine learning} e auxilia os desenvolvedores de compiladores no trabalhoso processo de ajuste fino das heurísticas que norteiam as de otimização de código.

Após analisar várias otimizações de compiladores, os autores constataram que muitas heurísticas têm um ponto focal: uma única função de prioridade ou custo que muitas vezes dita a eficácia de uma heurística. Uma função de prioridade leva em conta os fatores que afetam um determinado problema, e apresenta uma medida da importância relativa das opções disponíveis em um processo de otimização. Sendo assim, o \textit{Meta Optimization} consiste de um modelo de aprendizado que envolve programação genética para vasculhar, de maneira iterativa, o conjunto de soluções para a função de prioridade de uma otimização, em busca da alternativa que produza os melhores resultados.

A programação genética (GP) é um tipo de algoritmo evolutivo, isto é, um paradigma de inteligência artificial que se inspira na evolução das espécies por seleção natural, proposta por Charles Darwin \cite{darwin:59}. Na programação genética, os possíveis programas ou rotinas que resolvem um determinado problema são representados de maneira abstrata como indivíduos de uma população, definidos por um ``genoma'' que pode ser recombinado ou alterado de modo a criar novos indivíduos. O processo de obtenção da solução ótima consiste em, ao longo de várias iterações ou gerações, criar variabilidade na população através de reprodução cruzada, mutações ou recombinações, e em seguida efetuar a seleção dos indivíduos mais aptos, criados aleatoriamente \cite{koza:94}.

Na abordagem de Stephenson \textit{et al.} \cite{amarasinghe:03}, as possíveis heurísticas são submetidas ao processo de seleção, sendo cada uma representada como a árvore sintática abstrata da expressão que corresponde ao cálculo da função. O algoritmo começa criando uma população composta de expressões iniciais usadas como referência e outras expressões geradas aleatoriamente. Em seguida, o algoritmo determina o nível de \textit{fitness}, ou aptidão, de cada indivíduo, nesse caso correspondente à velocidade de execução do código gerado utilizando a função de prioridade na alocação de registradores, e é dado início ao processo de evolução. A Figura \ref{fig:stephenson} ilustra, nas Subfiguras (a) e (b), duas árvores sintáticas que correspondem a duas funções de prioridade; a Subfigura (c) mostra o resultado do cruzamento dos genomas de (a) e (b), enquanto (d) apresenta uma mutação na Subfigura (a).

\begin{figure}[hbt]
    \centering
    \includegraphics[width=\textwidth]{stephenson}
    \caption{Genomas das funções de prioridade, submetidas a operações de cruzamento e mutação. Extraído de Stephenson \textit{et al.} \cite{amarasinghe:03}.}
    \label{fig:stephenson}
\end{figure}

O algoritmo de alocação de registradores usado nos experimentos foi o de alocação prioritária, utilizando uma função de prioridade que representa o ganho de performance ao se manter um \textit{live range} em registradores, ao invés de se realizar \textit{spill}. A Equação \ref{eq:stephenson-1} mede o ganho de performance ao se manter uma variável em registradores no bloco $i$, onde $\mathit{ganho}_\textit{load}$ e $\mathit{ganho}_\textit{store}$ representam as economias ao se evitar \textit{loads} e \textit{stores} respectivamente; $\mathit{uses}_i$ e $\mathit{defs}_i$ são os números de usos e definições de uma variável no bloco $i$, enquanto $w_i$ é a frequência de execução de $i$. A Equação \ref{eq:stephenson-2} define a função prioritária de referência que foi utilizada para inicializar a população de treinamento, onde $V$ é um \textit{live range} e $N$ é o número de blocos que compõe $V$.

\begin{equation}
    \mathit{ganhos}_i = w_i (\mathit{ganho}_{\mathit{load}} \times \mathit{uses}_i + \mathit{ganho}_{\mathit{store}} \times \mathit{defs}_i)
    \label{eq:stephenson-1}
\end{equation}

\begin{equation}
    \mathit{prioridade}(V) = \frac{\sum_{i \in V} \mathit{ganhos}_i}{N}
    \label{eq:stephenson-2}
\end{equation}

Os experimentos realizados por Stephenson \textit{et al.} apresentaram um aumento médio de 11\% na velocidade de execução com as heurísticas especializadas obtidas pelo \textit{Meta Optimization}, isto é, treinando uma população para cada \textit{benchmark} de teste. Em experimentos buscando uma heurística de uso geral, utilizando diferentes \textit{benchmarks} para a mesma população, o aumento médio foi de 3\%, que, apesar de menor do que o obtido com as heurísticas especializadas, ainda se mostra um aumento significativo. A Figura \ref{fig:stephenson-resultados} mostra o \textit{plot} do nível de \textit{fitness} ao longo das gerações, para o treinamento das heurísticas especializadas e da heurística de uso geral, respectivamente.

\begin{figure}[hbt]
    \centering
    \includegraphics[scale=1.4]{stephenson-resultados}
    \caption{O eixo horizontal mostra o número de gerações, enquanto o eixo vertical apresenta o aumento na velocidade de execução. Extraído de Stephenson \textit{et al} \cite{amarasinghe:03}.}
    \label{fig:stephenson-resultados}
\end{figure}

\section{Coloração de Grafos via \textit{Deep Learning}} \label{sec:coloracao-deep-learning}

Em um trabalho de 2019, Lemos \textit{et al.} \cite{lemos:19} lidam com problema da coloração utilizando um modelo de rede neural em grafo (GNN), um tipo de rede neural capaz de representar informações extraídas dos nós de um grafo \cite{scarselli:09}. O modelo utiliza um sistema de memória que mantém representações multidimensionais das informações sobre os vértices, associados a um conjunto de cores, além de uma rede neural recorrente (RNN) que computa as atualizações no sistema. O processo envolve 32 iterações de troca de mensagens entre vértices adjacentes e entre vértices e cores, para que o modelo obtenha a viabilidade das colorações para cada vértice. Cada vértice então decide se o grafo de entrada permite uma coloração com $k$ cores.

O modelo foi treinado utilizando uma abordagem generativa. As instâncias de treinamento foram criadas tomando instâncias reais e modificando seu número cromático ao adicionar vértices no grafo; em seguida, ambas as instâncias eram adicionadas no conjunto de treinamento. O modelo atingiu 82\% de precisão para instâncias após entre 40 e 60 gerações de treinamento, e número de cores $k$ entre 3 e 7. Além disso, os autores observaram que o modelo treinado generaliza bem para valores de $k$ não vistos anteriormente e instâncias maiores.

Os pesquisadores discutem na publicação como o funcionamento interno do modelo influencia sua tomada de decisão. Eles afirmam que o modelo procura uma resposta positiva ao agrupar vértices de forma a aproximar aqueles que poderiam ter a mesma cor. Apesar de agrupar vértices adjacentes em uma proporção baixa, o modelo continua a fornecer respostas positivas. O número desejado de cores ($k$) é introduzido no modelo com representações iniciais aleatórias, evitando qualquer conhecimento prévio.

Eles propõem melhorias futuras, como a redução de conflitos dentro do próprio modelo como uma métrica de perda, mesmo com o aumento da complexidade temporal e espacial. Os autores destacam que seu trabalho evidencia como um modelo semelhante ao GNN pode ser ajustado para solucionar desafiadores problemas combinatórios, como a coloração de grafos, de maneira interpretável, gerando resultados precisos e construtivos.

Em 2020, Das \textit{et al.} \cite{das:20} publicaram um trabalho que também envolve a alocação via coloração de grafos empregando modelos de \textit{deep learning}, especificamente, o alocador utiliza uma abordagem híbrida, como os próprios autores assim o descreveram, dividida em duas etapas: uma consiste na coloração propriamente dita, feita por uma rede neural multicamadas, e a outra consiste de uma etapa de correção. Os autores buscaram encontrar novas heurísticas através do \textit{deep learning}, apresentando resultados comparáveis ou até melhores do que os dos alocadores convencionais por coloração de grafos.

A coloração do grafo de interferência é feita por uma rede neural recorrente (RNN) composta por várias camadas de LSTM, ou \textit{``long short-term memory''}. O LSTM é uma arquitetura de RNN que possui memória, sendo capaz de armazenar valores em intervalos arbitrários. Uma célula LSTM é formada por um conjunto de neurônios organizados em ``portas'' que controlam o fluxo de informação: uma porta \textit{input} para entrada, uma porta \textit{output} para saída e a porta \textit{forget}, que controla o esquecimento da informação. A Figura \ref{fig:lstm} ilustra a organização básica de uma célula LSTM.

\begin{figure}[hbt]
    \centering
    \includegraphics[width=.7\textwidth]{lstm}
    \caption{Extraído de Yu \textit{et al.} \cite{yu:19}.}
    \label{fig:lstm}
\end{figure}

A porta \textit{input} decide quais partes das novas informações devem ser armazenadas no estado atual, usando um sistema semelhante ao da porta \textit{forget}. A porta \textit{output} controla qual parte das informações no estado atual devem ser usadas, atribuindo um valor de 0 a 1 à informação, considerando os estados anterior e atual. A porta \textit{forget} determina quais informações descartar do estado anterior, atribuindo um valor entre 0 e 1 ao estado anterior em comparação com a entrada atual. Um valor próximo a 1 significa manter a informação, enquanto um valor próximo a 0 significa descartá-la. A produção seletiva de informações relevantes do estado atual permite que a rede LSTM mantenha dependências úteis de longo prazo para fazer previsões, tanto nos passos de tempo atuais quanto nos futuros \cite{yu:19, das:20}.

Visando maximizar a performance, o modelo foi arquitetado possuindo três camadas de células LSTM, com os estados ocultos de uma camada sendo repassados às células da camada seguinte. Os dados submetidos à camada de entrada da rede neural são as adjacências de cada vértice do grafo, sendo uma lista de adjacências $\mathit{adj}(v_i)$ para cada vértice $v_i$, e é produzido como saída uma sequência de cores $\mathit{cor}(v_i)$, cada qual correspondente à coloração de um vértice do grafo de interferência. A Figura \ref{fig:das-modelo} esquematiza a organização do modelo.

\begin{figure}[hbt]
    \centering
    \adjustbox{width=\textwidth}{\begin{tikzpicture}[text centered]
        \node (adj_1) {$\mathit{adj}(v_1)$};
        \node[draw, rounded corners, right = of adj_1] (lstm_11) {LSTM};
        \node[draw, rounded corners, right = of lstm_11] (lstm_12) {LSTM};
        \node[draw, rounded corners, right = of lstm_12] (lstm_13) {LSTM};
        \node[draw, circle, right = 2cm of lstm_13] (output_1) {ReLU};
        \node[right = of output_1] (cor_1) {$\mathit{cor}(v_1)$};

        \draw[->, -latex, very thick] (adj_1) -- (lstm_11);
        \draw[->, -latex, very thick] (lstm_11) -- (lstm_12);
        \draw[->, -latex, very thick] (lstm_12) -- (lstm_13);
        \draw[->, -latex, very thick] (lstm_13) -- (output_1);
        \draw[->, -latex, very thick] (output_1) -- (cor_1);

        \node[below = of adj_1] (adj_2) {$\mathit{adj}(v_2)$};
        \node[draw, rounded corners, right = of adj_2] (lstm_21) {LSTM};
        \node[draw, rounded corners, right = of lstm_21] (lstm_22) {LSTM};
        \node[draw, rounded corners, right = of lstm_22] (lstm_23) {LSTM};
        \node[draw, circle, right = 2cm of lstm_23] (output_2) {ReLU};
        \node[right = of output_2] (cor_2) {$\mathit{cor}(v_2)$};

        \draw[->, -latex, very thick] (adj_2) -- (lstm_21);
        \draw[->, -latex, very thick] (lstm_21) -- (lstm_22);
        \draw[->, -latex, very thick] (lstm_22) -- (lstm_23);
        \draw[->, -latex, very thick] (lstm_23) -- (output_2);
        \draw[->, -latex, very thick] (output_2) -- (cor_2);

        \node[below = 3mm of adj_2] (dots) {\Large $\vdots$};

        \node[below = 3mm of dots] (adj_n) {$\mathit{adj}(v_n)$};
        \node[draw, rounded corners, right = of adj_n] (lstm_n1) {LSTM};
        \node[draw, rounded corners, right = of lstm_n1] (lstm_n2) {LSTM};
        \node[draw, rounded corners, right = of lstm_n2] (lstm_n3) {LSTM};
        \node[draw, circle, right = 2cm of lstm_n3] (output_n) {ReLU};
        \node[right = of output_n] (cor_n) {$\mathit{cor}(v_n)$};

        \draw[->, -latex, very thick] (adj_n) -- (lstm_n1);
        \draw[->, -latex, very thick] (lstm_n1) -- (lstm_n2);
        \draw[->, -latex, very thick] (lstm_n2) -- (lstm_n3);
        \draw[->, -latex, very thick] (lstm_n3) -- (output_n);
        \draw[->, -latex, very thick] (output_n) -- (cor_n);

        \draw[dashed] ([xshift=-3mm, yshift=7mm] lstm_11.north west) rectangle ([xshift=3mm, yshift=-3mm] lstm_n1.south east);
        \node at ([yshift=4mm] lstm_11.north) {Camada 1};

        \draw[dashed] ([xshift=-3mm, yshift=7mm] lstm_12.north west) rectangle ([xshift=3mm, yshift=-3mm] lstm_n2.south east);
        \node at ([yshift=4mm] lstm_12.north) {Camada 2};

        \draw[dashed] ([xshift=-3mm, yshift=7mm] lstm_13.north west) rectangle ([xshift=3mm, yshift=-3mm] lstm_n3.south east);
        \node at ([yshift=4mm] lstm_13.north) {Camada 3};

        \draw[->, -latex, very thick] (lstm_13.east) -- (output_1.west);
        \draw[->, -latex, very thick] (lstm_13.east) -- (output_2.west);
        \draw[->, -latex, very thick] (lstm_n3.east) -- (output_1.west);
        
        \draw[->, -latex, very thick] (lstm_23.east) -- (output_1.west);
        
        \draw[->, -latex, very thick] (lstm_n3.east) -- (output_2.west);
        \draw[->, -latex, very thick] (lstm_13.east) -- (output_n.west);
        \draw[->, -latex, very thick] (lstm_23.east) -- (output_n.west);
        
    \end{tikzpicture}
    }
    \caption{Esquema da rede neural de coloração. Adaptado de Das \textit{et al.} \cite{das:20}.}
    \label{fig:das-modelo}
\end{figure}

Todavia, em alguns casos o modelo realiza colorações inválidas, onde dois vértices adjacentes possuem a mesma cor. Sendo assim, a coloração produzida como resultado pela rede neural é submetida a uma fase subsequente de correções, onde as colorações inválidas são corrigidas. Para o treinamento, foram utilizados grafos de até 100 vértices gerados aleatoriamente usando a biblioteca \texttt{very nauty}, disponível em linguagem C. O modelo foi validado utilizando os \textit{benchmarks} da suíte do SPEC CPU 2017, e o desempenho do alocador foi comparado ao do alocador \texttt{greedy} do LLVM, um \textit{framework} em código aberto que contém várias ferramentas para o desenvolvimento de compiladores 
\cite{lattner:04}. 

O desempenho foi medido em relação ao número de registradores necessários para obter uma coloração válida sem necessidade de \textit{spill}. Sendo assim, o desempenho foi medido utilizando cinco \textit{benchmarks}. Em um deles (\texttt{508.namd\_r}), o modelo de \textit{deep learning} apresentou um resultado pior do que o alocador do LLVM, sendo 5\% pior. Nos demais (\texttt{505.mcf\_r}, \texttt{557.xz\_r}, \texttt{541.leela\_r} e \texttt{502.gcc\_r}), a rede neural apresentou um desempenho superior, de 2\%, 2,5\%, 7\% e 5\%, respectivamente.

\section{Alocação de Registradores com \textit{Reinforcement Learning}}

Em 2023, VenktaKeerthy \textit{et al.} \cite{venkatakeerthy:23} apresentaram uma aplicação que realiza a alocação de registradores empregando técnicas de \textit{reinforcemente learning} hierárquico e as ferramentas do LLVM. Eles abstraíram o problema de alocação dividindo-o em uma série de tarefas, cada uma sendo realizada por um agente inteligente, que se integram maneira hierárquica ao gerador de código do LLVM através de um \textit{framework} gRPC. A aplicação realiza a coloração de grafos de maneira não-iterativa, também sendo capaz de efetuar \textit{live range splitting}.

De maneira semelhante ao modelo de coloração de Lemos \textit{et al.} \cite{lemos:19} (\ref{sec:coloracao-deep-learning}), o modelo de inteligência artificial de VenktaKeerthy \textit{et al.} \cite{venkatakeerthy:23} representa o grafo de interferência codificando as instruções da representação intermediária de máquina (MIR) do LLVM, que então compõe o \textit{input} de uma \textit{gated graph neural network} (GGNN). A GGNN mantém uma visão do estado grafo de interferência, e a mantém atualizada conforme as alocações são realizadas realizando troca constante de informações entre os vértices. Além disso, elas permitem a anotação dos nós e arestas com base em seus tipos e propriedades, levando em consideração essas informações durante o aprendizado das representações.

O alocador foi denominado \textit{RL4ReAl} é composto de quatro agentes que se encarregam, cada um, de uma tarefa específica do processo de alocação de registradores. São eles, em ordem hierárquica:

\begin{enumerate}
    \item \textbf{\textit{Node selector}} --- agente encarregado de selecionar um vértice $v \in G$ levando em conta o custo de \textit{spill} e que, por consequência, determina a ordem de alocação. A política aprendida é considerada boa com base no resultado final da alocação. Portanto, a recompensa para este agente também é modelada com base nas recompensas dos agentes de nível inferior;

    \item \textbf{\textit{Task selector}} --- agente encarregado de decidir se uma variável específica será alocada para um registrador ou passará pelo processo de \textit{live range splitting}, levando em conta o número de registradores disponíveis, o número de interferências, seu tempo de vida e o custo de \textit{spill}. Sua recompensa é determinada com base na coloração da variável. Se a tarefa escolhida for o \textit{splitting}, então a recompensa é adiada até a decisão de coloração.

    \item \textbf{\textit{Splitter}} --- agente responsável por determinar os pontos de divisão dos \textit{live ranges} eleitos para \textit{splitting}. Para prever onde dividir os \textit{live ranges}, são levados em conta os custos de \textit{spil} em cada uso da variável, as distâncias entre usos sucessivos da variável e a codificação do vértice correspondente na GGNN. A recompensa é dada pela variação nas distâncias dos usos sucessivos da variável que sofreu \textit{split} e pela variação do número de interferências no grafo. Se a variação das distâncias de uso for maior do que a das interferências, a divisão é benéfica.

    \item \textbf{\textit{Coloring agent}} --- agente de nível inferior que aprende a selecionar uma cor válida para uma variável ou realizar \textit{spill} caso não haja registrador disponível. Sua recompensa é determinada pelo custo de \textit{spill} da variável: se o tempo de vida for colorido, o reforço é positivo; no entanto, se a variável for mapeada para memória, o reforço é negativo. Dessa forma, o agente aprende a priorizar a coloração de variáveis com custo mais elevado.
\end{enumerate}

Esses agentes constituem o modelo de \textit{reinforcement learning} implementado em linguagem Python, que interage com o otimizador do LLVM através de um \textit{framework} gRPC, que permite a realização de chamadas remotas entre programas diferentes. Dessa maneira, informações do grafo de interferência construído com as ferramentas do LLVM são enviadas para os agentes, e as decisões tomadas pelo \textit{Splitter} ou pelo \textit{Coloring agent} são devolvidas de modo a atualizar a representação do grafo presente no LLVM. A Figura \ref{fig:venktakeerthy} esquematiza a interação entre ambos os componentes através do gRPC.

\begin{figure}
    \centering
    \begin{tikzpicture}[align=center, minimum width=1.8cm, thick, minimum height=1.2cm, arrow/.style={->, -latex, thick}]
        \node[draw] (selector) {\textit{Node}\\\textit{selector}};
        \node[draw, below = 1cm of selector] (task) {\textit{Task}\\\textit{selector}};
        \node[draw, below left = 1cm and 0.25cm of task] (splitter) {\textit{Splitter}};
        \node[draw, below right = 1cm and 0.25cm of task] (coloring) {\textit{Coloring}\\\textit{agent}};
        
        \node[left = 2cm of selector] (ggnn) {\adjustbox{scale=0.4}{\begin{tikzpicture}[text centered, draw=black, node distance=1.5cm, >=Stealth, thick]
            
            % Camada de entrada
            \foreach \i in {1,...,4}
                \node[circle, draw, minimum size=0.75cm] (I-\i) at (0,-\i) {};
            
            % Camada oculta
            \foreach \h [count=\hi] in {1,...,4} % Ajuste o número de nós na camada oculta
                \node[circle, draw, minimum size=0.75cm, right = 1cm of I-\h] (H-\h) {};
    
            % Conexões entre camadas
            \foreach \i in {1,...,4}
                \foreach \h in {1,...,4}
                    \draw[-] (I-\i) -- (H-\h);
            \end{tikzpicture}}};
        \node[above = -4.8mm of ggnn] {GGNN};
        \node[left = 50mm of task, draw] (gRPC) {\textit{framework}\\gRPC};
        \node[left = 15mm of gRPC, draw] (grafo) {Grafo de\\interferência};
        \node[above = 1cm of grafo] (frontend) {\Large $\vdots$};
        \node[below = 1cm of grafo, draw] (gerador){Gerador de\\código};

        \draw[arrow] (frontend) -- (grafo);
        \draw[arrow] (grafo) -- (gerador);

        \draw[arrow] ([yshift=3mm] grafo.east) -- ([yshift=3mm] gRPC.west) % node[above] {Codificações}
        ;

        \draw[arrow] ([yshift=-3mm] gRPC.west) -- ([yshift=-3mm] grafo.east);

        \coordinate (z) at ([yshift=3mm] gRPC.east);
        \coordinate (w) at ([yshift=-3mm] gRPC.east);
        \coordinate (a) at (ggnn |- z);
        \coordinate (b) at (ggnn |- w);
        \coordinate (c) at ([yshift=-4mm] splitter.south);
        \coordinate (d) at ([yshift=-4mm] coloring.south);
        \coordinate (y) at (ggnn |- c);
        \draw[arrow] (a) -- (ggnn);
        \draw[arrow] (b) -- (w);
        \draw[-, thick] (z) -- (a);
        \draw[-, thick] (b) -- (y);
        \draw[-, thick] (c) -- (y);
        \draw[-, thick] (c) -- (splitter.south);
        \draw[-, thick] (c) -- (d);
        \draw[-, thick] (coloring.south) -- (d);

        \draw[arrow] (selector) -- (task);
        \draw[arrow] (task) -- (splitter.north east);
        \draw[arrow] (task) -- (coloring.north west);
        \draw[arrow] (ggnn) -- (selector);

        \coordinate (f) at ([xshift=3mm] grafo.east);
        \coordinate (g) at ([yshift=-7mm] gerador.south);
        \coordinate (h) at ([xshift=-3mm] grafo.west);
        % \coordinate (i) at ([yshift=3mm] frontend.north);
        \coordinate (m) at ([yshift=5mm] ggnn.north);
        \draw[dashed] (f |- g) rectangle (h |- m); 
        \coordinate (midpoint1) at ($(h |- m)!0.5!(f |- m)$);
        \node[above = 1mm of midpoint1] {LLVM};
        
        \coordinate (j) at ([xshift=3mm] coloring.east);
        \coordinate (k) at ([yshift=-7mm] coloring.south);
        \coordinate (l) at (ggnn.west);
        \draw[dashed] (j |- k) rectangle (l |- m); %node[above right] {\textit{Framework} de \textit{Reinforcement Learning}};
        \coordinate (midpoint2) at ($(l |- m)!0.5!(j |- m)$);
        \node[above = 1mm of midpoint2] {\textit{Framework} de \textit{Reinforcement Learning}};
    \end{tikzpicture}
    \caption{Esquema da interação entre o LLVM e o \textit{framework} de \textit{RL}. Adaptado de VenkataKeerthy \textit{et al.} \cite{venkatakeerthy:23}.}
    \label{fig:venktakeerthy}
\end{figure}

A tomada de decisões por parte dos agentes foi modelada como um processo de decisão de Markov, que representa processos de decisão sequenciais estocásticos em um sistema de estados, onde funções de custo e transição dependem apenas do estado atual do sistema e da ação atual \cite{puterman:90}. A Figura \ref{fig:markov} mostra um sistema de decisão de Markov, onde os nós do grafo representam os estados e as arestas representam as ações, cada uma possuindo, respectivamente, a recompensa pela tomada da ação e a probabilidade de se chegar ao estado seguinte.

\begin{figure}[hbt]
    \centering
    \begin{tikzpicture}[scale=2.0, thick, ->, -latex, thick]
        \node[draw, circle] (s1) {$S_1$};    
        \node[draw, circle, right = of s1] (s2) {$S_2$};

        \draw (s1) edge[bend left] node[above] {$a_{1,1}\ \{5,1/2\}$} (s2);
        \draw (s1) edge[bend right] node[below] {$a_{1,2}\ \{10,1\}$} (s2);
        \draw (s1) edge[loop left] node[left] {$a_{1,1}\ \{5,1/2\}$} (s1);
        \draw (s2) edge[loop right] node[right] {$a_{2,1}\ \{-1,1\}$} (s2);
    \end{tikzpicture}
    \caption{Esquema de uma instância de processo de decisão de Markov. Adaptado de Puterman \cite{puterman:90}.}
    \label{fig:markov}
\end{figure}

O treinamento foi realizado com 2 mil arquivos coletados aleatoriamente da suíte do SPEC CPU 2017 e da biblioteca \texttt{boost}, escrita em linguagem C++, utilizando uma estratégia de \textit{Proximal Policy Optimization} (PPO) para o ajuste das políticas de tomada de decisão dos agentes. Foram treinados dois modelos distintos, um empregando apenas recompensas locais e outro utilizando recompensas globais e locais simultaneamente.

O desempenho das alocações foi medido em termos do tempo de execução do programa resultante e número de acessos à memória, comparando o resultado de 18 \textit{benchmarks} dos SPEC CPU 2006 e 2017 utilizando-se o modelo de \textit{reinforcement learning} e os alocadores tradicionais do LLVM (\textit{basic}, \textit{greedy} e \textit{pbqp}). Os testes foram efetuados em duas máquinas: uma possuindo 32 GB de RAM, com um processador Intel Xeon SkyLake W2133 \textit{hexa-core} (arquitetura x86), e uma de 8 GB de RAM, ARM Cortex A72 \textit{dual-core} (arquitetura AArch64).

Em média, os resultados apresentados pelo \textit{RL4ReAl} são comparáveis ou ligeiramente melhores do que os dos alocadores do LLVM. Na arquitetura x86, o modelo de \textit{reinforcement learning} apresentou melhorias em tempo de execução de 1,59\% e 0,96\% em relação aos alocadores \textit{basic} e \textit{pbqp} respectivamente; em contrapartida, houve uma piora de 0,61\% com relação ao alocador \textit{greedy}. Em AArch64, o \textit{RL4ReAl} apresentou melhorias em comparação aos três alocadores do LLVM: 1,18\% sobre o \textit{basic}, 0,22\% sobre o \textit{pbqp} e 0,26\% em relação ao \textit{greedy}. O alocador de VenkataKeerthy \textit{et al.} também efetuou uma menor quantidade de \textit{reloads} por \textit{spill} em comparação aos alocadores do LLVM para ambas arquiteturas, demonstrando que os agentes de RL foram capazes de aprender uma boa política de escolha de variáveis para \textit{spill}.

De maneira análoga, Kim \textit{et al.} \cite{kim:22} propuseram a incorporação de técnicas de \textit{reinforcement learning} na alocação de registradores via PBQP. Os autores desenvolveram um alocador para sistemas embarcados voltados para teste de chips DRAM, empregando um modelo que resolve o PBQP utilizando heurísticas baseadas em processos estocásticos e aprimoradas através do aprendizado por reforço.

No trabalho de Kim \textit{et al.}, o grafo de resolução do PBQP é representado na forma de uma série de vetores numéricos, que são usados como entrada para uma rede convolucional em grafo (GCN). Então, o modelo realiza a alocação utilizando \textit{Monte Carlo search tree} (MCTS), uma técnica de busca em árvore baseada em processos estocásticos, muito empregada por agentes inteligentes destinados a jogos. O algoritmo da MCTS consiste em explorar uma árvore, que corresponde às possibilidades de jogadas ou ações em um sistema, com base em conhecimento prévio e realizando simulações a cada novo nó descoberto, de modo a adaptar a base de conhecimento com os dados das melhores jogadas para se atingir um resultado pré-determinado.

O treinamento do modelo foi conduzido utilizando-se grafos aleatórios gerados pelo modelo de Erdos-Rényi. Para a avaliação do desempenho do modelo, foram empregados 24 exemplos do \textit{suite} de testes do LLVM, e os resultados em tempo de execução foram comparados aos dos alocadores \textit{fast}, \textit{greedy} e \textit{pbqp} do LLVM; a opção \textit{fast}, que emprega alocação de registradores local, serviu como referência para os resultados obtidos. O modelo de RL de Kim \textit{et al.} apresentou resultados piores em apenas 2 \textit{benchmarks}, quando comparado com o alodador PBQP do LLVM.

\section{Outros trabalhos}

Alguns outros trabalhos abordam a aplicação de técnicas de \textit{machine learning} em problemas de otimização como a coloração de grafos de maneira geral, sem necessariamente ter relação com a alocação de registradores. Schuetz \textit{et al.} \cite{schuetz:22}, por exemplo, desenvolveram um método de coloração de grafos com redes neurais inspirado por princípios da física. Goudet \textit{et al.} \cite{goudet:22} propuseram um modelo combinando \textit{deep learning} e um \textit{framework} memético, um tipo de algoritmo evolutivo, executável em GPUs. 

Dodaro \textit{et al.} \cite{dodaro:22} treinaram um agente de \textit{deep learning} para gerar heurísticas visando resolver a coloração de grafos utilizando \textit{answer set programming} (ASP), um paradigma de inteligência artificial para a representação de bases de conhecimento e lógica. Musliu e Schwengerer \cite{musliu:13} identificaram 78 características dos grafos que podem indicar quais algoritmos se utilizar para realizar a coloração, e sugeriram técnicas de aprendizado de máquina para automaticamente classificar grafos e automaticamente escolher o melhor método de resolução.

No mais, a integração do aprendizado de máquina na alocação de registradores permanece ainda um horizonte relativamente inexplorado, com poucos trabalhos publicados na área. No entanto, esses seletos trabalhos já se mostram suficientemente promissores para motivar futuros esforços de pesquisa, visando desenvolver alocadores de registradores que empregam \textit{machine learning}.

\chapter{Próximas Etapas}

Com este texto finalizado, estão concluídas as fases de levantamento bibliográfico, análise das técnicas e de escrita da versão preliminar do Trabalho de Conclusão de Curso, objetivo final da disciplina de TCC I. Sendo assim, o restante deste trabalho, que engloba a realização de alguma contribuição apoiada nos conhecimentos pesquisados e aqui descritos, será desenvolvido como parte da disciplina de TCC II. A contribuição por sua vez consistirá de um trabalho de implementação, seguido de coleta de dados e análise comparativa com as ferramentas e técnicas do estado da arte. Os resultados dessa etapa serão incluídos neste texto para compor as versões para banca e final do TCC.

Dadas as tarefas definidas previamente no projeto de TCC, temos a lista atualizada de atividades, juntamente ao cronograma apresentado na Tabela \ref{tab:cronograma}:

\begin{enumerate}
 \item Levantamento bibliográfico (concluído);
 \item Análise das técnicas e estudo das ferramentas (concluído);
 \item Escrita da versão preliminar (concluído);
 \item Planejamento da implementação (em curso);
 \item Implementação;
 \item Coleta e análise dos resultados;
 \item Escrita da versão para banca/final.
\end{enumerate}

\begin{table}[H] \centering
\caption{Cronograma de Execução}
\label{tab:cronograma}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}  \hline
\textit{Ativ.}\textbackslash \textit{mês} & ago. & set. & out. & nov. & dez. & jan. & fev. & mar. & abr. & mai.  \\ \hline
Ativ. 1 & $\checkmark$ & & & & & & & & & \\ \hline
Ativ. 2 & $\checkmark$ & $\checkmark$ & $\checkmark$ & & & & & & &  \\ \hline
Ativ. 3 & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & & &  & & \\ \hline
Ativ. 4 & & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ &  &  & & \\ \hline
Ativ. 5 & & & & & & $\bullet$ & $\bullet$ & $\bullet$ & & \\ \hline
Ativ. 6 & & & &  &  & & $\bullet$ & $\bullet$ & $\bullet$ & \\ \hline
Ativ. 7 & & & &  &  & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ \\ \hline
\end{tabular}
\end{table}

% ----------------------------------------------------------
% ELEMENTOS PÓS-TEXTUAIS
% ----------------------------------------------------------
\postextual


% ----------------------------------------------------------
% Referências bibliográficas
% ----------------------------------------------------------
\bibliography{abntex2-modelo-references}


% ----------------------------------------------------------
% Glossário
% ----------------------------------------------------------
%
% Consulte o manual da classe abntex2 para orientações sobre o glossário.
%
%\glossary

% ----------------------------------------------------------
% Apêndices
% ----------------------------------------------------------

% ---
% Apêndices (elemento opcional)
%
% São textos ou documentos elaborados pelo autor do trabalho a fim complementar
% a sua argumentação.
% ---
% \begin{apendicesenv}

% % Imprime uma página indicando o início dos apêndices
% \partapendices

% % ----------------------------------------------------------
% % \chapter{Quisque libero justo}
% % ----------------------------------------------------------

% \lipsum[50]/

% \end{apendicesenv}
% % ---


% % ----------------------------------------------------------
% % Anexos (elemento opcional)
% %
% % São textos ou documentos, não elaborado pelo autor do trabalho que podem servir como
% % ilustração, comprovação ou que contribua de forma relevante com o conteúdo já apresentado.
% % ----------------------------------------------------------

% % ---
% % Inicia os anexos
% % ---
% \begin{anexosenv}

% % Imprime uma página indicando o início dos anexos
% \partanexos

% % ---
% % \chapter{Morbi ultrices rutrum lorem.}
% % ---
% % \lipsum[30]

% \end{anexosenv}


% % ----------------------------------------------------------
% % Trabalhos publicados pelo autor
% %
% % Elemento obrigatório para as dissertações e teses do Programa
% % de Pós-graduação em Ciência da Computação da UEL.
% % (TCCs e monografias não precisam incluir essa seção)
% % ----------------------------------------------------------
% \chapter*{Trabalhos Publicados pelo Autor}
% \addcontentsline{toc}{chapter}{Trabalhos Publicados pelo Autor}

% \noindent
% Trabalhos publicados pelo autor durante o programa.

% % Elemento OBRIGATÓRIO somente para teses de doutorado e dissertações de mestrado no template DC/UEL).
% % Listar publicações principais do trabalho (i.e., diretamente relacionados ao tema) e complementares, quando existirem.
% % Listar em ordem decrescente de importância e/ou em ordem decrescente de ano de publicação.

% \vspace{12pt}

% \noindent
% Publicações principais do trabalho.

% \begin{enumerate}

% \item Jose da silva, autor2 da silva, orientador da silva, \textbf{Título do artigo}, local onde foi
% publicado, mês/ano, editora, número de página, isbn, etc. (Qualis CC 2017, xx)

% \item Jose da silva, autor2 da silva, orientador da silva, \textbf{Título do artigo}, local onde foi
% publicado, mês/ano, editora, número de página, isbn, etc. (Qualis CC 2017, xx)

% \item Jose da silva, autor2 da silva, orientador da silva, \textbf{Título do artigo}, local onde foi
% publicado, mês/ano, editora, número de página, isbn, etc. (Qualis CC 2017, xx)

% \end{enumerate}

% \noindent
% Publicações complementares.

% \begin{enumerate}

% \item Jose da silva, autor2 da silva, orientador da silva, \textbf{Título do artigo}, local onde foi
% publicado, mês/ano, editora, número de página, isbn, etc. (Qualis CC 2017, xx)

% \item Jose da silva, autor2 da silva, orientador da silva, etc. \textbf{Título do artigo}, local onde foi
% publicado, mês/ano, editora, número de página, isbn, (Qualis CC 2017, xx)

% \end{enumerate}


%---------------------------------------------------------------------
% INDICE REMISSIVO (elemento opcional)
%---------------------------------------------------------------------
% Requer incluir instruções \index{...} no decorrer do texto, para marcar os termos a serem indexados

\printindex

\end{document}
